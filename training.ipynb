{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e07bd2-5cdb-4528-a578-e8b519b2401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Found 50 sequences for gesture 'swipe_left' in dataset\\dynamic\\swipe_left\n",
      "Found 50 sequences for gesture 'swipe_right' in dataset\\dynamic\\swipe_right\n",
      "Found 50 sequences for gesture 'swipe_up' in dataset\\dynamic\\swipe_up\n",
      "Found 50 sequences for gesture 'swipe_down' in dataset\\dynamic\\swipe_down\n",
      "Found 50 sequences for gesture 'screenshot' in dataset\\dynamic\\screenshot\n",
      "Found 50 sequences for gesture 'drop' in dataset\\dynamic\\drop\n",
      "Found 50 sequences for gesture 'like' in dataset\\static\\like\n",
      "Found 50 sequences for gesture 'dislike' in dataset\\static\\dislike\n",
      "Found 50 sequences for gesture 'sos' in dataset\\dynamic\\sos\n",
      "Found 50 sequences for gesture 'peace' in dataset\\static\\peace\n",
      "\n",
      "--- Initial Class Distribution ---\n",
      "swipe_left: 50 samples\n",
      "swipe_right: 50 samples\n",
      "swipe_up: 50 samples\n",
      "swipe_down: 50 samples\n",
      "screenshot: 50 samples\n",
      "drop: 50 samples\n",
      "like: 50 samples\n",
      "dislike: 50 samples\n",
      "sos: 50 samples\n",
      "peace: 50 samples\n",
      "-------------------------\n",
      "\n",
      "Preprocessing data...\n",
      "\n",
      "--- Balancing dataset ---\n",
      "\n",
      "--- Class Distribution After Balancing and Augmentation ---\n",
      "swipe_left: 150 samples\n",
      "swipe_right: 150 samples\n",
      "swipe_up: 150 samples\n",
      "swipe_down: 150 samples\n",
      "screenshot: 150 samples\n",
      "drop: 150 samples\n",
      "like: 50 samples\n",
      "dislike: 50 samples\n",
      "sos: 150 samples\n",
      "peace: 50 samples\n",
      "-------------------------\n",
      "\n",
      "✅ Loaded and processed 1200 sequences with shape (1200, 60, 63)\n",
      "Building enhanced gesture recognition model...\n",
      "\n",
      "🧠 Starting k-fold cross-validation training...\n",
      "\n",
      "Sanity check - Training split shape: (960, 60, 63)\n",
      "Sanity check - Validation split shape: (240, 60, 63)\n",
      "\n",
      "--- Training Fold 1/5 ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,160</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,224</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,288</span> │ sequence_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                               │                           │                 │ spatial_dropout1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                               │                           │                 │ spatial_dropout1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">328,704</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │ spatial_dropout1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ spatial_dropout1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)          │                           │                 │ spatial_dropout1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                               │                           │                 │ spatial_dropout1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ global_average_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ sequence_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m63\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m12,160\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m20,224\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m28,288\u001b[0m │ sequence_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m192\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ spatial_dropout1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                               │                           │                 │ spatial_dropout1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                               │                           │                 │ spatial_dropout1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m192\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m328,704\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ bidirectional_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m164,352\u001b[0m │ spatial_dropout1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)               │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │ bidirectional_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ spatial_dropout1d_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)            │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ multi_head_attention          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m66,048\u001b[0m │ spatial_dropout1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)          │                           │                 │ spatial_dropout1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                               │                           │                 │ spatial_dropout1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ layer_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m256\u001b[0m │ multi_head_attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ global_average_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ layer_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)      │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m16,512\u001b[0m │ global_average_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │             \u001b[38;5;34m650\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">647,754</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m647,754\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">646,986</span> (2.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m646,986\u001b[0m (2.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1994 - loss: 2.8547\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76667, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.2012 - loss: 2.8439 - val_accuracy: 0.7667 - val_loss: 1.0755 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4784 - loss: 1.6873\n",
      "Epoch 2: val_accuracy improved from 0.76667 to 0.82917, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.4824 - loss: 1.6787 - val_accuracy: 0.8292 - val_loss: 0.6223 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6873 - loss: 1.2243\n",
      "Epoch 3: val_accuracy improved from 0.82917 to 0.87083, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6881 - loss: 1.2223 - val_accuracy: 0.8708 - val_loss: 0.3990 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7767 - loss: 0.9340\n",
      "Epoch 4: val_accuracy did not improve from 0.87083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7748 - loss: 0.9384 - val_accuracy: 0.8542 - val_loss: 0.2943 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8087 - loss: 0.7458\n",
      "Epoch 5: val_accuracy improved from 0.87083 to 0.92917, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8086 - loss: 0.7490 - val_accuracy: 0.9292 - val_loss: 0.2309 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8713 - loss: 0.6600\n",
      "Epoch 6: val_accuracy did not improve from 0.92917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8698 - loss: 0.6632 - val_accuracy: 0.9167 - val_loss: 0.2004 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8498 - loss: 0.6419\n",
      "Epoch 7: val_accuracy did not improve from 0.92917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8494 - loss: 0.6440 - val_accuracy: 0.9125 - val_loss: 0.1905 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8772 - loss: 0.6210\n",
      "Epoch 8: val_accuracy did not improve from 0.92917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8773 - loss: 0.6205 - val_accuracy: 0.9250 - val_loss: 0.1702 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8940 - loss: 0.5553\n",
      "Epoch 9: val_accuracy improved from 0.92917 to 0.93750, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8936 - loss: 0.5559 - val_accuracy: 0.9375 - val_loss: 0.1585 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8940 - loss: 0.5749\n",
      "Epoch 10: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8943 - loss: 0.5738 - val_accuracy: 0.9083 - val_loss: 0.1525 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9018 - loss: 0.5303\n",
      "Epoch 11: val_accuracy did not improve from 0.93750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9018 - loss: 0.5309 - val_accuracy: 0.9167 - val_loss: 0.1452 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8947 - loss: 0.5088\n",
      "Epoch 12: val_accuracy improved from 0.93750 to 0.94583, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8949 - loss: 0.5087 - val_accuracy: 0.9458 - val_loss: 0.1459 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9043 - loss: 0.5305\n",
      "Epoch 13: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9045 - loss: 0.5287 - val_accuracy: 0.9208 - val_loss: 0.1393 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9214 - loss: 0.4292\n",
      "Epoch 14: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9214 - loss: 0.4291 - val_accuracy: 0.9417 - val_loss: 0.1372 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9005 - loss: 0.4667\n",
      "Epoch 15: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9006 - loss: 0.4671 - val_accuracy: 0.9458 - val_loss: 0.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9129 - loss: 0.4293\n",
      "Epoch 16: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9126 - loss: 0.4324 - val_accuracy: 0.9167 - val_loss: 0.1361 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9141 - loss: 0.4279\n",
      "Epoch 17: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9140 - loss: 0.4289 - val_accuracy: 0.9167 - val_loss: 0.1313 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9076 - loss: 0.4441\n",
      "Epoch 18: val_accuracy improved from 0.94583 to 0.95000, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9078 - loss: 0.4426 - val_accuracy: 0.9500 - val_loss: 0.1277 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9188 - loss: 0.4230\n",
      "Epoch 19: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9188 - loss: 0.4230 - val_accuracy: 0.9250 - val_loss: 0.1319 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9330 - loss: 0.3825\n",
      "Epoch 20: val_accuracy did not improve from 0.95000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9328 - loss: 0.3831 - val_accuracy: 0.9375 - val_loss: 0.1326 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9205 - loss: 0.4290\n",
      "Epoch 21: val_accuracy improved from 0.95000 to 0.95417, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9202 - loss: 0.4293 - val_accuracy: 0.9542 - val_loss: 0.1254 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9354 - loss: 0.3572\n",
      "Epoch 22: val_accuracy improved from 0.95417 to 0.95833, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9351 - loss: 0.3582 - val_accuracy: 0.9583 - val_loss: 0.1199 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9367 - loss: 0.3540\n",
      "Epoch 23: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9360 - loss: 0.3561 - val_accuracy: 0.9500 - val_loss: 0.1147 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9353 - loss: 0.3587\n",
      "Epoch 24: val_accuracy improved from 0.95833 to 0.96250, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9352 - loss: 0.3590 - val_accuracy: 0.9625 - val_loss: 0.1148 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9385 - loss: 0.3087\n",
      "Epoch 25: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9383 - loss: 0.3112 - val_accuracy: 0.9625 - val_loss: 0.1133 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9360 - loss: 0.3495\n",
      "Epoch 26: val_accuracy improved from 0.96250 to 0.96667, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9359 - loss: 0.3503 - val_accuracy: 0.9667 - val_loss: 0.1076 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9318 - loss: 0.3768\n",
      "Epoch 27: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9317 - loss: 0.3768 - val_accuracy: 0.9542 - val_loss: 0.1091 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9444 - loss: 0.3411\n",
      "Epoch 28: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9438 - loss: 0.3426 - val_accuracy: 0.9542 - val_loss: 0.1143 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9366 - loss: 0.3378\n",
      "Epoch 29: val_accuracy improved from 0.96667 to 0.97083, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9365 - loss: 0.3383 - val_accuracy: 0.9708 - val_loss: 0.1035 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9407 - loss: 0.3130\n",
      "Epoch 30: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9405 - loss: 0.3142 - val_accuracy: 0.9583 - val_loss: 0.1106 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9470 - loss: 0.3083\n",
      "Epoch 31: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9468 - loss: 0.3091 - val_accuracy: 0.9583 - val_loss: 0.1026 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9418 - loss: 0.3379\n",
      "Epoch 32: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9418 - loss: 0.3377 - val_accuracy: 0.9667 - val_loss: 0.0870 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9387 - loss: 0.3367\n",
      "Epoch 33: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9386 - loss: 0.3366 - val_accuracy: 0.9625 - val_loss: 0.0865 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9467 - loss: 0.2977\n",
      "Epoch 34: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9467 - loss: 0.2974 - val_accuracy: 0.9708 - val_loss: 0.0728 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9524 - loss: 0.2448\n",
      "Epoch 35: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9519 - loss: 0.2465 - val_accuracy: 0.9667 - val_loss: 0.0576 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9421 - loss: 0.3059\n",
      "Epoch 36: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9420 - loss: 0.3053 - val_accuracy: 0.9708 - val_loss: 0.0645 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9534 - loss: 0.2324\n",
      "Epoch 37: val_accuracy improved from 0.97083 to 0.97917, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9535 - loss: 0.2326 - val_accuracy: 0.9792 - val_loss: 0.0506 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9589 - loss: 0.2448\n",
      "Epoch 38: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9590 - loss: 0.2444 - val_accuracy: 0.9750 - val_loss: 0.0590 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9720 - loss: 0.1834\n",
      "Epoch 39: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9716 - loss: 0.1845 - val_accuracy: 0.9792 - val_loss: 0.0571 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9497 - loss: 0.3175\n",
      "Epoch 40: val_accuracy improved from 0.97917 to 0.99167, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.3140 - val_accuracy: 0.9917 - val_loss: 0.0368 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9683 - loss: 0.1908\n",
      "Epoch 41: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9681 - loss: 0.1914 - val_accuracy: 0.9833 - val_loss: 0.0388 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9703 - loss: 0.1593\n",
      "Epoch 42: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9704 - loss: 0.1593 - val_accuracy: 0.9667 - val_loss: 0.0793 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9760 - loss: 0.1631\n",
      "Epoch 43: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9757 - loss: 0.1645 - val_accuracy: 0.9917 - val_loss: 0.0279 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9671 - loss: 0.1602\n",
      "Epoch 44: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9672 - loss: 0.1604 - val_accuracy: 0.9875 - val_loss: 0.0329 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9789 - loss: 0.1469\n",
      "Epoch 45: val_accuracy improved from 0.99167 to 0.99583, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9787 - loss: 0.1472 - val_accuracy: 0.9958 - val_loss: 0.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9869 - loss: 0.1101\n",
      "Epoch 46: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9865 - loss: 0.1121 - val_accuracy: 0.9708 - val_loss: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9802 - loss: 0.1580\n",
      "Epoch 47: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.1578 - val_accuracy: 0.9792 - val_loss: 0.0501 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9804 - loss: 0.1469\n",
      "Epoch 48: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9802 - loss: 0.1475 - val_accuracy: 0.9917 - val_loss: 0.0189 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9808 - loss: 0.1411\n",
      "Epoch 49: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9804 - loss: 0.1433 - val_accuracy: 0.9792 - val_loss: 0.0652 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9645 - loss: 0.1672\n",
      "Epoch 50: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9649 - loss: 0.1667 - val_accuracy: 0.9917 - val_loss: 0.0196 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9845 - loss: 0.1240\n",
      "Epoch 51: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9839 - loss: 0.1253 - val_accuracy: 0.9958 - val_loss: 0.0110 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9713 - loss: 0.1325\n",
      "Epoch 52: val_accuracy improved from 0.99583 to 1.00000, saving model to best_model_fold1.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9713 - loss: 0.1332 - val_accuracy: 1.0000 - val_loss: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9942 - loss: 0.0694\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9941 - loss: 0.0695 - val_accuracy: 0.9875 - val_loss: 0.0303 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9871 - loss: 0.0764\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9870 - loss: 0.0774 - val_accuracy: 1.0000 - val_loss: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9876 - loss: 0.0934\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9874 - loss: 0.0933 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9866 - loss: 0.1020\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9867 - loss: 0.1012 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9843 - loss: 0.0909\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9842 - loss: 0.0921 - val_accuracy: 1.0000 - val_loss: 0.0029 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9870 - loss: 0.1065\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9871 - loss: 0.1055 - val_accuracy: 0.9833 - val_loss: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9949 - loss: 0.0591\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9948 - loss: 0.0598 - val_accuracy: 0.9917 - val_loss: 0.0112 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9891 - loss: 0.0646\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9892 - loss: 0.0651 - val_accuracy: 1.0000 - val_loss: 0.0024 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9913 - loss: 0.0506\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9912 - loss: 0.0514 - val_accuracy: 0.9958 - val_loss: 0.0101 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9901 - loss: 0.0602\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9901 - loss: 0.0607 - val_accuracy: 0.9833 - val_loss: 0.0492 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9858 - loss: 0.1057\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9857 - loss: 0.1072 - val_accuracy: 0.9958 - val_loss: 0.0164 - learning_rate: 5.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9915 - loss: 0.0515\n",
      "Epoch 64: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9916 - loss: 0.0516 - val_accuracy: 0.9958 - val_loss: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9939 - loss: 0.0544\n",
      "Epoch 65: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0543 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9948 - loss: 0.0426\n",
      "Epoch 66: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9946 - loss: 0.0437 - val_accuracy: 1.0000 - val_loss: 6.8934e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9913 - loss: 0.0446\n",
      "Epoch 67: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9913 - loss: 0.0448 - val_accuracy: 0.9917 - val_loss: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9879 - loss: 0.0895\n",
      "Epoch 68: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9880 - loss: 0.0886 - val_accuracy: 1.0000 - val_loss: 6.1181e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0355\n",
      "Epoch 69: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9956 - loss: 0.0354 - val_accuracy: 1.0000 - val_loss: 0.0010 - learning_rate: 5.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9938 - loss: 0.0318\n",
      "Epoch 70: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9937 - loss: 0.0330 - val_accuracy: 1.0000 - val_loss: 9.3999e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9921 - loss: 0.0901\n",
      "Epoch 71: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9922 - loss: 0.0892 - val_accuracy: 1.0000 - val_loss: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9924 - loss: 0.0415\n",
      "Epoch 72: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9924 - loss: 0.0422 - val_accuracy: 1.0000 - val_loss: 0.0018 - learning_rate: 5.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9962 - loss: 0.0337\n",
      "Epoch 73: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9962 - loss: 0.0341 - val_accuracy: 0.9917 - val_loss: 0.0424 - learning_rate: 5.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9902 - loss: 0.0795\n",
      "Epoch 74: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9903 - loss: 0.0783 - val_accuracy: 1.0000 - val_loss: 7.7566e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0315\n",
      "Epoch 75: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9963 - loss: 0.0319 - val_accuracy: 1.0000 - val_loss: 8.7131e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9924 - loss: 0.0524\n",
      "Epoch 76: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9922 - loss: 0.0542 - val_accuracy: 0.9875 - val_loss: 0.0339 - learning_rate: 5.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9980 - loss: 0.0361\n",
      "Epoch 77: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9980 - loss: 0.0358 - val_accuracy: 0.9958 - val_loss: 0.0242 - learning_rate: 5.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9966 - loss: 0.0543\n",
      "Epoch 78: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9964 - loss: 0.0548 - val_accuracy: 0.9958 - val_loss: 0.0116 - learning_rate: 5.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9952 - loss: 0.0564\n",
      "Epoch 79: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9952 - loss: 0.0561 - val_accuracy: 1.0000 - val_loss: 6.2923e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9967 - loss: 0.0380\n",
      "Epoch 80: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9967 - loss: 0.0377 - val_accuracy: 1.0000 - val_loss: 2.5789e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9971 - loss: 0.0198\n",
      "Epoch 81: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9971 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 3.8424e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9995 - loss: 0.0166\n",
      "Epoch 82: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9994 - loss: 0.0166 - val_accuracy: 1.0000 - val_loss: 1.7741e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 82: early stopping\n",
      "Restoring model weights from the end of the best epoch: 52.\n",
      "\n",
      "Fold 1 Classification Report:\n",
      "Fold 1 Accuracy: 1.0000\n",
      "\n",
      "--- Training Fold 2/5 ---\n",
      "Epoch 1/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2515 - loss: 2.6198\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66250, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.2573 - loss: 2.5954 - val_accuracy: 0.6625 - val_loss: 1.0620 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5556 - loss: 1.3608\n",
      "Epoch 2: val_accuracy improved from 0.66250 to 0.87500, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.5562 - loss: 1.3638 - val_accuracy: 0.8750 - val_loss: 0.5266 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6683 - loss: 1.0864\n",
      "Epoch 3: val_accuracy improved from 0.87500 to 0.89167, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6693 - loss: 1.0878 - val_accuracy: 0.8917 - val_loss: 0.3624 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7487 - loss: 0.9271\n",
      "Epoch 4: val_accuracy did not improve from 0.89167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7484 - loss: 0.9307 - val_accuracy: 0.8875 - val_loss: 0.2681 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8142 - loss: 0.7848\n",
      "Epoch 5: val_accuracy improved from 0.89167 to 0.89583, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8132 - loss: 0.7895 - val_accuracy: 0.8958 - val_loss: 0.2324 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8377 - loss: 0.6856\n",
      "Epoch 6: val_accuracy improved from 0.89583 to 0.92083, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8377 - loss: 0.6870 - val_accuracy: 0.9208 - val_loss: 0.1907 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8829 - loss: 0.6207\n",
      "Epoch 7: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8826 - loss: 0.6203 - val_accuracy: 0.9125 - val_loss: 0.1725 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9082 - loss: 0.5212\n",
      "Epoch 8: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9078 - loss: 0.5229 - val_accuracy: 0.9125 - val_loss: 0.1636 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8947 - loss: 0.5270\n",
      "Epoch 9: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8949 - loss: 0.5298 - val_accuracy: 0.9083 - val_loss: 0.1725 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8953 - loss: 0.5377\n",
      "Epoch 10: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8953 - loss: 0.5381 - val_accuracy: 0.9125 - val_loss: 0.1570 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9116 - loss: 0.4913\n",
      "Epoch 11: val_accuracy did not improve from 0.92083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9111 - loss: 0.4929 - val_accuracy: 0.9125 - val_loss: 0.1591 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9015 - loss: 0.5332\n",
      "Epoch 12: val_accuracy improved from 0.92083 to 0.92500, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9013 - loss: 0.5338 - val_accuracy: 0.9250 - val_loss: 0.1555 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9151 - loss: 0.4314\n",
      "Epoch 13: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9149 - loss: 0.4345 - val_accuracy: 0.9208 - val_loss: 0.1584 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9301 - loss: 0.4425\n",
      "Epoch 14: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9297 - loss: 0.4438 - val_accuracy: 0.9208 - val_loss: 0.1588 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9285 - loss: 0.4260\n",
      "Epoch 15: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9279 - loss: 0.4283 - val_accuracy: 0.9208 - val_loss: 0.1560 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9283 - loss: 0.4108\n",
      "Epoch 16: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9269 - loss: 0.4154 - val_accuracy: 0.9083 - val_loss: 0.1528 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9278 - loss: 0.4090\n",
      "Epoch 17: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9273 - loss: 0.4124 - val_accuracy: 0.9167 - val_loss: 0.1528 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9407 - loss: 0.3796\n",
      "Epoch 18: val_accuracy improved from 0.92500 to 0.95417, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9403 - loss: 0.3808 - val_accuracy: 0.9542 - val_loss: 0.1505 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9209 - loss: 0.4039\n",
      "Epoch 19: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9207 - loss: 0.4047 - val_accuracy: 0.9208 - val_loss: 0.1489 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9250 - loss: 0.3952\n",
      "Epoch 20: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9246 - loss: 0.3989 - val_accuracy: 0.9167 - val_loss: 0.1485 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9179 - loss: 0.4060\n",
      "Epoch 21: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9174 - loss: 0.4078 - val_accuracy: 0.9125 - val_loss: 0.1521 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9213 - loss: 0.3827\n",
      "Epoch 22: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9212 - loss: 0.3835 - val_accuracy: 0.9125 - val_loss: 0.1508 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9280 - loss: 0.3722\n",
      "Epoch 23: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9280 - loss: 0.3726 - val_accuracy: 0.9333 - val_loss: 0.1418 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9228 - loss: 0.3751\n",
      "Epoch 24: val_accuracy improved from 0.95417 to 0.97083, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9228 - loss: 0.3759 - val_accuracy: 0.9708 - val_loss: 0.1362 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9327 - loss: 0.3530\n",
      "Epoch 25: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9330 - loss: 0.3531 - val_accuracy: 0.9625 - val_loss: 0.1343 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9319 - loss: 0.3552\n",
      "Epoch 26: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9319 - loss: 0.3554 - val_accuracy: 0.9708 - val_loss: 0.1238 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9338 - loss: 0.3370\n",
      "Epoch 27: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9338 - loss: 0.3379 - val_accuracy: 0.9625 - val_loss: 0.1249 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9354 - loss: 0.3441\n",
      "Epoch 28: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9354 - loss: 0.3435 - val_accuracy: 0.9583 - val_loss: 0.1207 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9471 - loss: 0.3500\n",
      "Epoch 29: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9469 - loss: 0.3497 - val_accuracy: 0.9417 - val_loss: 0.1276 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9425 - loss: 0.3376\n",
      "Epoch 30: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9424 - loss: 0.3382 - val_accuracy: 0.9583 - val_loss: 0.1190 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9294 - loss: 0.3410\n",
      "Epoch 31: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9295 - loss: 0.3409 - val_accuracy: 0.9417 - val_loss: 0.1234 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9627 - loss: 0.2808\n",
      "Epoch 32: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9620 - loss: 0.2823 - val_accuracy: 0.9625 - val_loss: 0.0996 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9543 - loss: 0.3139\n",
      "Epoch 33: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9535 - loss: 0.3149 - val_accuracy: 0.9458 - val_loss: 0.1182 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9526 - loss: 0.2983\n",
      "Epoch 34: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9527 - loss: 0.2979 - val_accuracy: 0.9625 - val_loss: 0.1030 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9532 - loss: 0.3125\n",
      "Epoch 35: val_accuracy did not improve from 0.97083\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9530 - loss: 0.3128 - val_accuracy: 0.9667 - val_loss: 0.0965 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9533 - loss: 0.2949\n",
      "Epoch 36: val_accuracy improved from 0.97083 to 0.97500, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9530 - loss: 0.2950 - val_accuracy: 0.9750 - val_loss: 0.0883 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9452 - loss: 0.2716\n",
      "Epoch 37: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9452 - loss: 0.2719 - val_accuracy: 0.9667 - val_loss: 0.0708 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9687 - loss: 0.2270\n",
      "Epoch 38: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9683 - loss: 0.2287 - val_accuracy: 0.9750 - val_loss: 0.0697 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9568 - loss: 0.2691\n",
      "Epoch 39: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9566 - loss: 0.2700 - val_accuracy: 0.9667 - val_loss: 0.1049 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9530 - loss: 0.2654\n",
      "Epoch 40: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9531 - loss: 0.2654 - val_accuracy: 0.9667 - val_loss: 0.0869 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9589 - loss: 0.2127\n",
      "Epoch 41: val_accuracy improved from 0.97500 to 0.99167, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9592 - loss: 0.2121 - val_accuracy: 0.9917 - val_loss: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9652 - loss: 0.2257\n",
      "Epoch 42: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9653 - loss: 0.2273 - val_accuracy: 0.9792 - val_loss: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9652 - loss: 0.2290\n",
      "Epoch 43: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9650 - loss: 0.2293 - val_accuracy: 0.9792 - val_loss: 0.0666 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9635 - loss: 0.2405\n",
      "Epoch 44: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9637 - loss: 0.2386 - val_accuracy: 0.9833 - val_loss: 0.0483 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9680 - loss: 0.2284\n",
      "Epoch 45: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9686 - loss: 0.2259 - val_accuracy: 0.9875 - val_loss: 0.0435 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9792 - loss: 0.1395\n",
      "Epoch 46: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9794 - loss: 0.1389 - val_accuracy: 0.9917 - val_loss: 0.0289 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9894 - loss: 0.0932\n",
      "Epoch 47: val_accuracy improved from 0.99167 to 0.99583, saving model to best_model_fold2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9892 - loss: 0.0939 - val_accuracy: 0.9958 - val_loss: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9789 - loss: 0.1923\n",
      "Epoch 48: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9787 - loss: 0.1930 - val_accuracy: 0.9875 - val_loss: 0.0457 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9659 - loss: 0.1943\n",
      "Epoch 49: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9663 - loss: 0.1919 - val_accuracy: 0.9875 - val_loss: 0.0564 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9808 - loss: 0.1255\n",
      "Epoch 50: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9810 - loss: 0.1249 - val_accuracy: 0.9875 - val_loss: 0.0603 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9832 - loss: 0.1130\n",
      "Epoch 51: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9832 - loss: 0.1125 - val_accuracy: 0.9958 - val_loss: 0.0197 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9797 - loss: 0.1307\n",
      "Epoch 52: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9801 - loss: 0.1291 - val_accuracy: 0.9917 - val_loss: 0.0301 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9896 - loss: 0.0877\n",
      "Epoch 53: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9896 - loss: 0.0885 - val_accuracy: 0.9958 - val_loss: 0.0240 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9861 - loss: 0.0892\n",
      "Epoch 54: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9864 - loss: 0.0899 - val_accuracy: 0.9875 - val_loss: 0.0582 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9747 - loss: 0.1974\n",
      "Epoch 55: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9747 - loss: 0.1978 - val_accuracy: 0.9875 - val_loss: 0.0347 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9946 - loss: 0.0833\n",
      "Epoch 56: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9945 - loss: 0.0832 - val_accuracy: 0.9917 - val_loss: 0.0241 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.0691\n",
      "Epoch 57: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9943 - loss: 0.0695 - val_accuracy: 0.9917 - val_loss: 0.0398 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9984 - loss: 0.0406\n",
      "Epoch 58: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9983 - loss: 0.0414 - val_accuracy: 0.9917 - val_loss: 0.0370 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9951 - loss: 0.0339\n",
      "Epoch 59: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9950 - loss: 0.0348 - val_accuracy: 0.9917 - val_loss: 0.0404 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9923 - loss: 0.0605\n",
      "Epoch 60: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9922 - loss: 0.0612 - val_accuracy: 0.9958 - val_loss: 0.0228 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9893 - loss: 0.0578\n",
      "Epoch 61: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9896 - loss: 0.0574 - val_accuracy: 0.9958 - val_loss: 0.0279 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9972 - loss: 0.0455\n",
      "Epoch 62: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9970 - loss: 0.0467 - val_accuracy: 0.9875 - val_loss: 0.0551 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9908 - loss: 0.0573\n",
      "Epoch 63: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9908 - loss: 0.0578 - val_accuracy: 0.9958 - val_loss: 0.0271 - learning_rate: 5.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9922 - loss: 0.0837\n",
      "Epoch 64: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9922 - loss: 0.0833 - val_accuracy: 0.9917 - val_loss: 0.0289 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9940 - loss: 0.0372\n",
      "Epoch 65: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9942 - loss: 0.0372 - val_accuracy: 0.9958 - val_loss: 0.0300 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9905 - loss: 0.0459\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 66: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9906 - loss: 0.0459 - val_accuracy: 0.9958 - val_loss: 0.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9969 - loss: 0.0532\n",
      "Epoch 67: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9967 - loss: 0.0533 - val_accuracy: 0.9958 - val_loss: 0.0316 - learning_rate: 2.5000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9895 - loss: 0.0426\n",
      "Epoch 68: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9896 - loss: 0.0427 - val_accuracy: 0.9958 - val_loss: 0.0301 - learning_rate: 2.5000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9887 - loss: 0.0644\n",
      "Epoch 69: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9890 - loss: 0.0637 - val_accuracy: 0.9875 - val_loss: 0.0529 - learning_rate: 2.5000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9981 - loss: 0.0380\n",
      "Epoch 70: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9980 - loss: 0.0387 - val_accuracy: 0.9958 - val_loss: 0.0328 - learning_rate: 2.5000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9946 - loss: 0.0484\n",
      "Epoch 71: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9946 - loss: 0.0489 - val_accuracy: 0.9958 - val_loss: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9966 - loss: 0.0618\n",
      "Epoch 72: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9966 - loss: 0.0609 - val_accuracy: 0.9917 - val_loss: 0.0493 - learning_rate: 2.5000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0253\n",
      "Epoch 73: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9986 - loss: 0.0258 - val_accuracy: 0.9917 - val_loss: 0.0366 - learning_rate: 2.5000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9859 - loss: 0.0642\n",
      "Epoch 74: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9861 - loss: 0.0635 - val_accuracy: 0.9958 - val_loss: 0.0296 - learning_rate: 2.5000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9952 - loss: 0.0307\n",
      "Epoch 75: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9953 - loss: 0.0305 - val_accuracy: 0.9958 - val_loss: 0.0302 - learning_rate: 2.5000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9996 - loss: 0.0150\n",
      "Epoch 76: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9995 - loss: 0.0152 - val_accuracy: 0.9958 - val_loss: 0.0309 - learning_rate: 2.5000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9998 - loss: 0.0180\n",
      "Epoch 77: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9998 - loss: 0.0186 - val_accuracy: 0.9958 - val_loss: 0.0308 - learning_rate: 2.5000e-04\n",
      "Epoch 77: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\n",
      "Fold 2 Classification Report:\n",
      "Fold 2 Accuracy: 0.9958\n",
      "\n",
      "--- Training Fold 3/5 ---\n",
      "Epoch 1/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1810 - loss: 2.8206\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75833, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 56ms/step - accuracy: 0.1835 - loss: 2.8110 - val_accuracy: 0.7583 - val_loss: 1.0788 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5092 - loss: 1.5644\n",
      "Epoch 2: val_accuracy did not improve from 0.75833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.5129 - loss: 1.5608 - val_accuracy: 0.7542 - val_loss: 0.6455 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6901 - loss: 1.0846\n",
      "Epoch 3: val_accuracy improved from 0.75833 to 0.85000, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6914 - loss: 1.0834 - val_accuracy: 0.8500 - val_loss: 0.4177 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7857 - loss: 0.8526\n",
      "Epoch 4: val_accuracy improved from 0.85000 to 0.85417, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7857 - loss: 0.8532 - val_accuracy: 0.8542 - val_loss: 0.3153 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8298 - loss: 0.7302\n",
      "Epoch 5: val_accuracy improved from 0.85417 to 0.87083, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8300 - loss: 0.7307 - val_accuracy: 0.8708 - val_loss: 0.2649 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8746 - loss: 0.5950\n",
      "Epoch 6: val_accuracy improved from 0.87083 to 0.91250, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.8742 - loss: 0.5965 - val_accuracy: 0.9125 - val_loss: 0.2115 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8861 - loss: 0.5648\n",
      "Epoch 7: val_accuracy improved from 0.91250 to 0.94583, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8856 - loss: 0.5667 - val_accuracy: 0.9458 - val_loss: 0.1770 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8814 - loss: 0.5449\n",
      "Epoch 8: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8812 - loss: 0.5468 - val_accuracy: 0.9292 - val_loss: 0.1573 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8747 - loss: 0.5384\n",
      "Epoch 9: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8748 - loss: 0.5387 - val_accuracy: 0.9292 - val_loss: 0.1458 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9011 - loss: 0.4946\n",
      "Epoch 10: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9010 - loss: 0.4954 - val_accuracy: 0.9292 - val_loss: 0.1454 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9049 - loss: 0.4675\n",
      "Epoch 11: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9051 - loss: 0.4676 - val_accuracy: 0.9292 - val_loss: 0.1392 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9079 - loss: 0.4419\n",
      "Epoch 12: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9077 - loss: 0.4449 - val_accuracy: 0.9292 - val_loss: 0.1360 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9138 - loss: 0.4269\n",
      "Epoch 13: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9137 - loss: 0.4275 - val_accuracy: 0.9292 - val_loss: 0.1401 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9188 - loss: 0.4286\n",
      "Epoch 14: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9186 - loss: 0.4299 - val_accuracy: 0.9292 - val_loss: 0.1393 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9260 - loss: 0.3841\n",
      "Epoch 15: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9254 - loss: 0.3874 - val_accuracy: 0.9292 - val_loss: 0.1385 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9160 - loss: 0.3997\n",
      "Epoch 16: val_accuracy did not improve from 0.94583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9159 - loss: 0.4003 - val_accuracy: 0.9292 - val_loss: 0.1380 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9266 - loss: 0.4030\n",
      "Epoch 17: val_accuracy improved from 0.94583 to 0.96667, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9265 - loss: 0.4036 - val_accuracy: 0.9667 - val_loss: 0.1312 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9192 - loss: 0.3871\n",
      "Epoch 18: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9192 - loss: 0.3888 - val_accuracy: 0.9292 - val_loss: 0.1231 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9292 - loss: 0.3612\n",
      "Epoch 19: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9289 - loss: 0.3628 - val_accuracy: 0.9500 - val_loss: 0.1218 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9242 - loss: 0.3920\n",
      "Epoch 20: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9242 - loss: 0.3921 - val_accuracy: 0.9625 - val_loss: 0.1171 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9354 - loss: 0.3259\n",
      "Epoch 21: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9355 - loss: 0.3262 - val_accuracy: 0.9417 - val_loss: 0.1218 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9339 - loss: 0.3574\n",
      "Epoch 22: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9337 - loss: 0.3581 - val_accuracy: 0.9458 - val_loss: 0.1315 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9333 - loss: 0.3461\n",
      "Epoch 23: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9331 - loss: 0.3472 - val_accuracy: 0.9500 - val_loss: 0.1048 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9347 - loss: 0.3299\n",
      "Epoch 24: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9346 - loss: 0.3306 - val_accuracy: 0.9458 - val_loss: 0.1193 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9456 - loss: 0.3414\n",
      "Epoch 25: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9457 - loss: 0.3405 - val_accuracy: 0.9542 - val_loss: 0.1058 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9503 - loss: 0.2642\n",
      "Epoch 26: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9502 - loss: 0.2647 - val_accuracy: 0.9583 - val_loss: 0.0983 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9403 - loss: 0.3256\n",
      "Epoch 27: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9402 - loss: 0.3256 - val_accuracy: 0.9500 - val_loss: 0.0991 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9427 - loss: 0.3052\n",
      "Epoch 28: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9427 - loss: 0.3062 - val_accuracy: 0.9625 - val_loss: 0.0936 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9574 - loss: 0.2644\n",
      "Epoch 29: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9568 - loss: 0.2659 - val_accuracy: 0.9625 - val_loss: 0.0885 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9560 - loss: 0.2661\n",
      "Epoch 30: val_accuracy did not improve from 0.96667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9552 - loss: 0.2677 - val_accuracy: 0.9500 - val_loss: 0.0897 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9608 - loss: 0.2388\n",
      "Epoch 31: val_accuracy improved from 0.96667 to 0.97917, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9605 - loss: 0.2393 - val_accuracy: 0.9792 - val_loss: 0.0657 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9531 - loss: 0.2379\n",
      "Epoch 32: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9530 - loss: 0.2391 - val_accuracy: 0.9708 - val_loss: 0.0635 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9625 - loss: 0.2174\n",
      "Epoch 33: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9621 - loss: 0.2189 - val_accuracy: 0.9583 - val_loss: 0.0949 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9614 - loss: 0.2065\n",
      "Epoch 34: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9613 - loss: 0.2068 - val_accuracy: 0.9708 - val_loss: 0.0700 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9672 - loss: 0.1924\n",
      "Epoch 35: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9670 - loss: 0.1932 - val_accuracy: 0.9750 - val_loss: 0.0759 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9734 - loss: 0.1563\n",
      "Epoch 36: val_accuracy did not improve from 0.97917\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9730 - loss: 0.1579 - val_accuracy: 0.9500 - val_loss: 0.0894 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9684 - loss: 0.1832\n",
      "Epoch 37: val_accuracy improved from 0.97917 to 0.98333, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9682 - loss: 0.1836 - val_accuracy: 0.9833 - val_loss: 0.0545 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9715 - loss: 0.1720\n",
      "Epoch 38: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9715 - loss: 0.1721 - val_accuracy: 0.9708 - val_loss: 0.0734 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9687 - loss: 0.1712\n",
      "Epoch 39: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9686 - loss: 0.1742 - val_accuracy: 0.9667 - val_loss: 0.0750 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9835 - loss: 0.1303\n",
      "Epoch 40: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9826 - loss: 0.1321 - val_accuracy: 0.9583 - val_loss: 0.1367 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9733 - loss: 0.1433\n",
      "Epoch 41: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9734 - loss: 0.1432 - val_accuracy: 0.9667 - val_loss: 0.0944 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9913 - loss: 0.0997\n",
      "Epoch 42: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9907 - loss: 0.1020 - val_accuracy: 0.9750 - val_loss: 0.0797 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9827 - loss: 0.1306\n",
      "Epoch 43: val_accuracy did not improve from 0.98333\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9823 - loss: 0.1326 - val_accuracy: 0.9458 - val_loss: 0.2213 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9670 - loss: 0.2065\n",
      "Epoch 44: val_accuracy improved from 0.98333 to 0.99167, saving model to best_model_fold3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9670 - loss: 0.2061 - val_accuracy: 0.9917 - val_loss: 0.0450 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9850 - loss: 0.1373\n",
      "Epoch 45: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9847 - loss: 0.1386 - val_accuracy: 0.9917 - val_loss: 0.0422 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9636 - loss: 0.1531\n",
      "Epoch 46: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9639 - loss: 0.1527 - val_accuracy: 0.9917 - val_loss: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9893 - loss: 0.0793\n",
      "Epoch 47: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9893 - loss: 0.0795 - val_accuracy: 0.9750 - val_loss: 0.0712 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9880 - loss: 0.0718\n",
      "Epoch 48: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9878 - loss: 0.0722 - val_accuracy: 0.9917 - val_loss: 0.0451 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9930 - loss: 0.0582\n",
      "Epoch 49: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9929 - loss: 0.0584 - val_accuracy: 0.9833 - val_loss: 0.0709 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9899 - loss: 0.0546\n",
      "Epoch 50: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9900 - loss: 0.0547 - val_accuracy: 0.9583 - val_loss: 0.1437 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9895 - loss: 0.1223\n",
      "Epoch 51: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9893 - loss: 0.1218 - val_accuracy: 0.9792 - val_loss: 0.1171 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9901 - loss: 0.0758\n",
      "Epoch 52: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9897 - loss: 0.0773 - val_accuracy: 0.9792 - val_loss: 0.0964 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9887 - loss: 0.0882\n",
      "Epoch 53: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9886 - loss: 0.0885 - val_accuracy: 0.9917 - val_loss: 0.0579 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9925 - loss: 0.0741\n",
      "Epoch 54: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9922 - loss: 0.0751 - val_accuracy: 0.9667 - val_loss: 0.1027 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9910 - loss: 0.1054\n",
      "Epoch 55: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9910 - loss: 0.1051 - val_accuracy: 0.9917 - val_loss: 0.0418 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9915 - loss: 0.0772\n",
      "Epoch 56: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9914 - loss: 0.0768 - val_accuracy: 0.9917 - val_loss: 0.0427 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9946 - loss: 0.0523\n",
      "Epoch 57: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9946 - loss: 0.0528 - val_accuracy: 0.9917 - val_loss: 0.0383 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9856 - loss: 0.0962\n",
      "Epoch 58: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9856 - loss: 0.0973 - val_accuracy: 0.9917 - val_loss: 0.0555 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.0634\n",
      "Epoch 59: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9945 - loss: 0.0634 - val_accuracy: 0.9875 - val_loss: 0.0505 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0427\n",
      "Epoch 60: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9948 - loss: 0.0434 - val_accuracy: 0.9875 - val_loss: 0.0513 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9941 - loss: 0.0464\n",
      "Epoch 61: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9941 - loss: 0.0470 - val_accuracy: 0.9708 - val_loss: 0.1301 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9918 - loss: 0.0589\n",
      "Epoch 62: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.0585 - val_accuracy: 0.9875 - val_loss: 0.0648 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9958 - loss: 0.0375\n",
      "Epoch 63: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9958 - loss: 0.0378 - val_accuracy: 0.9875 - val_loss: 0.0609 - learning_rate: 5.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9952 - loss: 0.0489\n",
      "Epoch 64: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.0492 - val_accuracy: 0.9833 - val_loss: 0.0902 - learning_rate: 5.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0388\n",
      "Epoch 65: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9935 - loss: 0.0391 - val_accuracy: 0.9917 - val_loss: 0.0677 - learning_rate: 5.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9887 - loss: 0.0516\n",
      "Epoch 66: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9890 - loss: 0.0514 - val_accuracy: 0.9917 - val_loss: 0.0494 - learning_rate: 5.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9928 - loss: 0.0631\n",
      "Epoch 67: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9929 - loss: 0.0625 - val_accuracy: 0.9792 - val_loss: 0.0986 - learning_rate: 5.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0252\n",
      "Epoch 68: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0259 - val_accuracy: 0.9917 - val_loss: 0.0553 - learning_rate: 5.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.0411\n",
      "Epoch 69: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9953 - loss: 0.0413 - val_accuracy: 0.9917 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9975 - loss: 0.0341\n",
      "Epoch 70: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9975 - loss: 0.0342 - val_accuracy: 0.9917 - val_loss: 0.0538 - learning_rate: 5.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9987 - loss: 0.0249\n",
      "Epoch 71: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9986 - loss: 0.0260 - val_accuracy: 0.9792 - val_loss: 0.1137 - learning_rate: 5.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9930 - loss: 0.0615\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9930 - loss: 0.0620 - val_accuracy: 0.9750 - val_loss: 0.1631 - learning_rate: 5.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0378\n",
      "Epoch 73: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9957 - loss: 0.0376 - val_accuracy: 0.9875 - val_loss: 0.0547 - learning_rate: 2.5000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9988 - loss: 0.0263\n",
      "Epoch 74: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9988 - loss: 0.0263 - val_accuracy: 0.9875 - val_loss: 0.0692 - learning_rate: 2.5000e-04\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000299CB7FF0A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000299CB7FF0A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3 Classification Report:\n",
      "Fold 3 Accuracy: 0.9917\n",
      "\n",
      "--- Training Fold 4/5 ---\n",
      "Epoch 1/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1593 - loss: 2.9294\n",
      "Epoch 1: val_accuracy improved from -inf to 0.45833, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 57ms/step - accuracy: 0.1613 - loss: 2.9199 - val_accuracy: 0.4583 - val_loss: 1.4442 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4645 - loss: 1.6184\n",
      "Epoch 2: val_accuracy improved from 0.45833 to 0.68750, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4678 - loss: 1.6172 - val_accuracy: 0.6875 - val_loss: 0.7563 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6304 - loss: 1.1835\n",
      "Epoch 3: val_accuracy improved from 0.68750 to 0.79583, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.6312 - loss: 1.1833 - val_accuracy: 0.7958 - val_loss: 0.4737 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7499 - loss: 0.9237\n",
      "Epoch 4: val_accuracy improved from 0.79583 to 0.92500, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.7501 - loss: 0.9242 - val_accuracy: 0.9250 - val_loss: 0.2670 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7923 - loss: 0.8346\n",
      "Epoch 5: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.7923 - loss: 0.8357 - val_accuracy: 0.9250 - val_loss: 0.2040 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8552 - loss: 0.6896\n",
      "Epoch 6: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8549 - loss: 0.6908 - val_accuracy: 0.9125 - val_loss: 0.1738 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8857 - loss: 0.5703\n",
      "Epoch 7: val_accuracy did not improve from 0.92500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8852 - loss: 0.5727 - val_accuracy: 0.9250 - val_loss: 0.1494 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8861 - loss: 0.5458\n",
      "Epoch 8: val_accuracy improved from 0.92500 to 0.93333, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.8857 - loss: 0.5482 - val_accuracy: 0.9333 - val_loss: 0.1379 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8912 - loss: 0.5419\n",
      "Epoch 9: val_accuracy improved from 0.93333 to 0.93750, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8913 - loss: 0.5425 - val_accuracy: 0.9375 - val_loss: 0.1269 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9069 - loss: 0.4948\n",
      "Epoch 10: val_accuracy improved from 0.93750 to 0.94167, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9062 - loss: 0.4963 - val_accuracy: 0.9417 - val_loss: 0.1268 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9128 - loss: 0.4905\n",
      "Epoch 11: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9125 - loss: 0.4911 - val_accuracy: 0.9375 - val_loss: 0.1236 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9068 - loss: 0.4324\n",
      "Epoch 12: val_accuracy did not improve from 0.94167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9061 - loss: 0.4372 - val_accuracy: 0.9375 - val_loss: 0.1221 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9116 - loss: 0.4557\n",
      "Epoch 13: val_accuracy improved from 0.94167 to 0.95417, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9115 - loss: 0.4561 - val_accuracy: 0.9542 - val_loss: 0.1238 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9214 - loss: 0.4259\n",
      "Epoch 14: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9212 - loss: 0.4262 - val_accuracy: 0.9417 - val_loss: 0.1176 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9192 - loss: 0.3854\n",
      "Epoch 15: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9191 - loss: 0.3869 - val_accuracy: 0.9542 - val_loss: 0.1156 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9390 - loss: 0.3423\n",
      "Epoch 16: val_accuracy did not improve from 0.95417\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9380 - loss: 0.3462 - val_accuracy: 0.9375 - val_loss: 0.1165 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9304 - loss: 0.3457\n",
      "Epoch 17: val_accuracy improved from 0.95417 to 0.95833, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9298 - loss: 0.3494 - val_accuracy: 0.9583 - val_loss: 0.1082 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9340 - loss: 0.3589\n",
      "Epoch 18: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9336 - loss: 0.3602 - val_accuracy: 0.9375 - val_loss: 0.1152 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9276 - loss: 0.3941\n",
      "Epoch 19: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9275 - loss: 0.3944 - val_accuracy: 0.9458 - val_loss: 0.1102 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9447 - loss: 0.3027\n",
      "Epoch 20: val_accuracy improved from 0.95833 to 0.96250, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9437 - loss: 0.3084 - val_accuracy: 0.9625 - val_loss: 0.1027 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9343 - loss: 0.3762\n",
      "Epoch 21: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9342 - loss: 0.3766 - val_accuracy: 0.9500 - val_loss: 0.1068 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9276 - loss: 0.3607\n",
      "Epoch 22: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9276 - loss: 0.3618 - val_accuracy: 0.9375 - val_loss: 0.1069 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9429 - loss: 0.3169\n",
      "Epoch 23: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9424 - loss: 0.3193 - val_accuracy: 0.9625 - val_loss: 0.0940 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9392 - loss: 0.3052\n",
      "Epoch 24: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9387 - loss: 0.3094 - val_accuracy: 0.9542 - val_loss: 0.1050 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9404 - loss: 0.3339\n",
      "Epoch 25: val_accuracy improved from 0.96250 to 0.96667, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9398 - loss: 0.3350 - val_accuracy: 0.9667 - val_loss: 0.0921 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9524 - loss: 0.2570\n",
      "Epoch 26: val_accuracy improved from 0.96667 to 0.97083, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9520 - loss: 0.2594 - val_accuracy: 0.9708 - val_loss: 0.0795 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9502 - loss: 0.2610\n",
      "Epoch 27: val_accuracy improved from 0.97083 to 0.97500, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9500 - loss: 0.2627 - val_accuracy: 0.9750 - val_loss: 0.0701 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9408 - loss: 0.2861\n",
      "Epoch 28: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9409 - loss: 0.2862 - val_accuracy: 0.9708 - val_loss: 0.0794 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9414 - loss: 0.2912\n",
      "Epoch 29: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9411 - loss: 0.2928 - val_accuracy: 0.9417 - val_loss: 0.0966 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9513 - loss: 0.2530\n",
      "Epoch 30: val_accuracy improved from 0.97500 to 0.97917, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9512 - loss: 0.2538 - val_accuracy: 0.9792 - val_loss: 0.0686 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9597 - loss: 0.2197\n",
      "Epoch 31: val_accuracy improved from 0.97917 to 0.98750, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9595 - loss: 0.2202 - val_accuracy: 0.9875 - val_loss: 0.0612 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9592 - loss: 0.2168\n",
      "Epoch 32: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9592 - loss: 0.2174 - val_accuracy: 0.9833 - val_loss: 0.0581 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9520 - loss: 0.2405\n",
      "Epoch 33: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9520 - loss: 0.2408 - val_accuracy: 0.9833 - val_loss: 0.0579 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9630 - loss: 0.2202\n",
      "Epoch 34: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9630 - loss: 0.2203 - val_accuracy: 0.9875 - val_loss: 0.0446 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9713 - loss: 0.1989\n",
      "Epoch 35: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9705 - loss: 0.2010 - val_accuracy: 0.9667 - val_loss: 0.0757 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9576 - loss: 0.1887\n",
      "Epoch 36: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9574 - loss: 0.1907 - val_accuracy: 0.9875 - val_loss: 0.0556 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9567 - loss: 0.2062\n",
      "Epoch 37: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9569 - loss: 0.2064 - val_accuracy: 0.9792 - val_loss: 0.0611 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9720 - loss: 0.1573\n",
      "Epoch 38: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9716 - loss: 0.1591 - val_accuracy: 0.9667 - val_loss: 0.0790 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9481 - loss: 0.2494\n",
      "Epoch 39: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9476 - loss: 0.2509 - val_accuracy: 0.9875 - val_loss: 0.0693 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9656 - loss: 0.1960\n",
      "Epoch 40: val_accuracy did not improve from 0.98750\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9655 - loss: 0.1962 - val_accuracy: 0.9833 - val_loss: 0.0653 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9629 - loss: 0.1969\n",
      "Epoch 41: val_accuracy improved from 0.98750 to 0.99167, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9632 - loss: 0.1970 - val_accuracy: 0.9917 - val_loss: 0.0626 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9778 - loss: 0.1453\n",
      "Epoch 42: val_accuracy improved from 0.99167 to 0.99583, saving model to best_model_fold4.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9773 - loss: 0.1476 - val_accuracy: 0.9958 - val_loss: 0.0573 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9716 - loss: 0.1799\n",
      "Epoch 43: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9714 - loss: 0.1802 - val_accuracy: 0.9792 - val_loss: 0.0721 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9686 - loss: 0.1726\n",
      "Epoch 44: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9684 - loss: 0.1738 - val_accuracy: 0.9875 - val_loss: 0.0696 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9728 - loss: 0.1629\n",
      "Epoch 45: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9724 - loss: 0.1643 - val_accuracy: 0.9875 - val_loss: 0.0700 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9679 - loss: 0.1853\n",
      "Epoch 46: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9678 - loss: 0.1854 - val_accuracy: 0.9958 - val_loss: 0.0451 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9701 - loss: 0.1639\n",
      "Epoch 47: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9697 - loss: 0.1649 - val_accuracy: 0.9833 - val_loss: 0.0647 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9774 - loss: 0.1283\n",
      "Epoch 48: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9774 - loss: 0.1284 - val_accuracy: 0.9875 - val_loss: 0.0649 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9898 - loss: 0.1008\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 49: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9892 - loss: 0.1031 - val_accuracy: 0.9917 - val_loss: 0.0568 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9668 - loss: 0.1422\n",
      "Epoch 50: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9675 - loss: 0.1423 - val_accuracy: 0.9917 - val_loss: 0.0548 - learning_rate: 2.5000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9830 - loss: 0.1339\n",
      "Epoch 51: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9825 - loss: 0.1344 - val_accuracy: 0.9917 - val_loss: 0.0582 - learning_rate: 2.5000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9920 - loss: 0.0758\n",
      "Epoch 52: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9919 - loss: 0.0767 - val_accuracy: 0.9917 - val_loss: 0.0588 - learning_rate: 2.5000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9879 - loss: 0.0799\n",
      "Epoch 53: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9881 - loss: 0.0797 - val_accuracy: 0.9917 - val_loss: 0.0567 - learning_rate: 2.5000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9885 - loss: 0.0780\n",
      "Epoch 54: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9885 - loss: 0.0780 - val_accuracy: 0.9875 - val_loss: 0.0615 - learning_rate: 2.5000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9839 - loss: 0.0973\n",
      "Epoch 55: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9841 - loss: 0.0968 - val_accuracy: 0.9917 - val_loss: 0.0551 - learning_rate: 2.5000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9866 - loss: 0.0783\n",
      "Epoch 56: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9868 - loss: 0.0777 - val_accuracy: 0.9917 - val_loss: 0.0500 - learning_rate: 2.5000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.0597\n",
      "Epoch 57: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9937 - loss: 0.0597 - val_accuracy: 0.9917 - val_loss: 0.0581 - learning_rate: 2.5000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9962 - loss: 0.0547\n",
      "Epoch 58: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9962 - loss: 0.0547 - val_accuracy: 0.9917 - val_loss: 0.0550 - learning_rate: 2.5000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9891 - loss: 0.0717\n",
      "Epoch 59: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9890 - loss: 0.0719 - val_accuracy: 0.9875 - val_loss: 0.0647 - learning_rate: 2.5000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9915 - loss: 0.0903\n",
      "Epoch 60: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9916 - loss: 0.0889 - val_accuracy: 0.9917 - val_loss: 0.0561 - learning_rate: 2.5000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9950 - loss: 0.0461\n",
      "Epoch 61: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9949 - loss: 0.0470 - val_accuracy: 0.9917 - val_loss: 0.0610 - learning_rate: 2.5000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9902 - loss: 0.0523\n",
      "Epoch 62: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9903 - loss: 0.0522 - val_accuracy: 0.9917 - val_loss: 0.0589 - learning_rate: 2.5000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9805 - loss: 0.1115\n",
      "Epoch 63: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9811 - loss: 0.1096 - val_accuracy: 0.9958 - val_loss: 0.0486 - learning_rate: 2.5000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9955 - loss: 0.0492\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9955 - loss: 0.0492 - val_accuracy: 0.9917 - val_loss: 0.0558 - learning_rate: 2.5000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9951 - loss: 0.0422\n",
      "Epoch 65: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9951 - loss: 0.0424 - val_accuracy: 0.9917 - val_loss: 0.0518 - learning_rate: 1.2500e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0370\n",
      "Epoch 66: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0372 - val_accuracy: 0.9958 - val_loss: 0.0472 - learning_rate: 1.2500e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0270\n",
      "Epoch 67: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0276 - val_accuracy: 0.9917 - val_loss: 0.0501 - learning_rate: 1.2500e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.0375\n",
      "Epoch 68: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9954 - loss: 0.0374 - val_accuracy: 0.9917 - val_loss: 0.0666 - learning_rate: 1.2500e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0320\n",
      "Epoch 69: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9982 - loss: 0.0322 - val_accuracy: 0.9917 - val_loss: 0.0627 - learning_rate: 1.2500e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9934 - loss: 0.0380\n",
      "Epoch 70: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9934 - loss: 0.0389 - val_accuracy: 0.9917 - val_loss: 0.0626 - learning_rate: 1.2500e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9998 - loss: 0.0264\n",
      "Epoch 71: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0265 - val_accuracy: 0.9917 - val_loss: 0.0630 - learning_rate: 1.2500e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0269\n",
      "Epoch 72: val_accuracy did not improve from 0.99583\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0268 - val_accuracy: 0.9917 - val_loss: 0.0655 - learning_rate: 1.2500e-04\n",
      "Epoch 72: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000299B77C3AC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000299B77C3AC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4 Classification Report:\n",
      "Fold 4 Accuracy: 0.9958\n",
      "\n",
      "--- Training Fold 5/5 ---\n",
      "Epoch 1/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1654 - loss: 2.8581\n",
      "Epoch 1: val_accuracy improved from -inf to 0.65833, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 54ms/step - accuracy: 0.1688 - loss: 2.8450 - val_accuracy: 0.6583 - val_loss: 1.3397 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4829 - loss: 1.7430\n",
      "Epoch 2: val_accuracy improved from 0.65833 to 0.75000, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.4863 - loss: 1.7329 - val_accuracy: 0.7500 - val_loss: 0.7119 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6310 - loss: 1.1734\n",
      "Epoch 3: val_accuracy improved from 0.75000 to 0.86667, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.6328 - loss: 1.1723 - val_accuracy: 0.8667 - val_loss: 0.4874 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7383 - loss: 0.9476\n",
      "Epoch 4: val_accuracy did not improve from 0.86667\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.7390 - loss: 0.9482 - val_accuracy: 0.8667 - val_loss: 0.3559 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7931 - loss: 0.8517\n",
      "Epoch 5: val_accuracy improved from 0.86667 to 0.87917, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.7935 - loss: 0.8495 - val_accuracy: 0.8792 - val_loss: 0.2400 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8082 - loss: 0.7927\n",
      "Epoch 6: val_accuracy improved from 0.87917 to 0.94167, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8092 - loss: 0.7904 - val_accuracy: 0.9417 - val_loss: 0.1785 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8700 - loss: 0.6038\n",
      "Epoch 7: val_accuracy improved from 0.94167 to 0.95833, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.8700 - loss: 0.6039 - val_accuracy: 0.9583 - val_loss: 0.1267 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8779 - loss: 0.6392\n",
      "Epoch 8: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8781 - loss: 0.6384 - val_accuracy: 0.9500 - val_loss: 0.1192 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8806 - loss: 0.5723\n",
      "Epoch 9: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8810 - loss: 0.5709 - val_accuracy: 0.9292 - val_loss: 0.1213 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8904 - loss: 0.5294\n",
      "Epoch 10: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8906 - loss: 0.5288 - val_accuracy: 0.9458 - val_loss: 0.1155 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9078 - loss: 0.4981\n",
      "Epoch 11: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9075 - loss: 0.4989 - val_accuracy: 0.9458 - val_loss: 0.1107 - learning_rate: 5.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9112 - loss: 0.4767\n",
      "Epoch 12: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9108 - loss: 0.4774 - val_accuracy: 0.9583 - val_loss: 0.1067 - learning_rate: 5.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8988 - loss: 0.4544\n",
      "Epoch 13: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8986 - loss: 0.4556 - val_accuracy: 0.9500 - val_loss: 0.1049 - learning_rate: 5.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9093 - loss: 0.4331\n",
      "Epoch 14: val_accuracy did not improve from 0.95833\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4340 - val_accuracy: 0.9500 - val_loss: 0.1088 - learning_rate: 5.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9122 - loss: 0.4188\n",
      "Epoch 15: val_accuracy improved from 0.95833 to 0.96250, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9122 - loss: 0.4186 - val_accuracy: 0.9625 - val_loss: 0.1047 - learning_rate: 5.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9181 - loss: 0.4005\n",
      "Epoch 16: val_accuracy did not improve from 0.96250\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9182 - loss: 0.4002 - val_accuracy: 0.9375 - val_loss: 0.1039 - learning_rate: 5.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9186 - loss: 0.4258\n",
      "Epoch 17: val_accuracy improved from 0.96250 to 0.97083, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9184 - loss: 0.4267 - val_accuracy: 0.9708 - val_loss: 0.1048 - learning_rate: 5.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9193 - loss: 0.4435\n",
      "Epoch 18: val_accuracy improved from 0.97083 to 0.97500, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9190 - loss: 0.4440 - val_accuracy: 0.9750 - val_loss: 0.1050 - learning_rate: 5.0000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9252 - loss: 0.3883\n",
      "Epoch 19: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9247 - loss: 0.3893 - val_accuracy: 0.9500 - val_loss: 0.1016 - learning_rate: 5.0000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9304 - loss: 0.3707\n",
      "Epoch 20: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9305 - loss: 0.3712 - val_accuracy: 0.9500 - val_loss: 0.0965 - learning_rate: 5.0000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9259 - loss: 0.3765\n",
      "Epoch 21: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9260 - loss: 0.3764 - val_accuracy: 0.9375 - val_loss: 0.0954 - learning_rate: 5.0000e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9344 - loss: 0.3286\n",
      "Epoch 22: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9341 - loss: 0.3298 - val_accuracy: 0.9500 - val_loss: 0.0947 - learning_rate: 5.0000e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9271 - loss: 0.3689\n",
      "Epoch 23: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9272 - loss: 0.3689 - val_accuracy: 0.9708 - val_loss: 0.0917 - learning_rate: 5.0000e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9405 - loss: 0.3366\n",
      "Epoch 24: val_accuracy did not improve from 0.97500\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9401 - loss: 0.3388 - val_accuracy: 0.9583 - val_loss: 0.0891 - learning_rate: 5.0000e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9220 - loss: 0.3823\n",
      "Epoch 25: val_accuracy improved from 0.97500 to 0.99167, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9224 - loss: 0.3811 - val_accuracy: 0.9917 - val_loss: 0.0818 - learning_rate: 5.0000e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9218 - loss: 0.3911\n",
      "Epoch 26: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9221 - loss: 0.3901 - val_accuracy: 0.9500 - val_loss: 0.0993 - learning_rate: 5.0000e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9300 - loss: 0.3543\n",
      "Epoch 27: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9303 - loss: 0.3543 - val_accuracy: 0.9583 - val_loss: 0.0759 - learning_rate: 5.0000e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9468 - loss: 0.3127\n",
      "Epoch 28: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9466 - loss: 0.3131 - val_accuracy: 0.9750 - val_loss: 0.0798 - learning_rate: 5.0000e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9487 - loss: 0.2791\n",
      "Epoch 29: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9481 - loss: 0.2805 - val_accuracy: 0.9375 - val_loss: 0.1013 - learning_rate: 5.0000e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9517 - loss: 0.2865\n",
      "Epoch 30: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9510 - loss: 0.2883 - val_accuracy: 0.9500 - val_loss: 0.1064 - learning_rate: 5.0000e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9291 - loss: 0.3598\n",
      "Epoch 31: val_accuracy did not improve from 0.99167\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9296 - loss: 0.3571 - val_accuracy: 0.9750 - val_loss: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9491 - loss: 0.2462\n",
      "Epoch 32: val_accuracy improved from 0.99167 to 0.99583, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9491 - loss: 0.2465 - val_accuracy: 0.9958 - val_loss: 0.0406 - learning_rate: 5.0000e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9492 - loss: 0.2407\n",
      "Epoch 33: val_accuracy improved from 0.99583 to 1.00000, saving model to best_model_fold5.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9494 - loss: 0.2407 - val_accuracy: 1.0000 - val_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9538 - loss: 0.2724\n",
      "Epoch 34: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9538 - loss: 0.2710 - val_accuracy: 0.9875 - val_loss: 0.0445 - learning_rate: 5.0000e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9384 - loss: 0.2654\n",
      "Epoch 35: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9390 - loss: 0.2646 - val_accuracy: 0.9833 - val_loss: 0.0381 - learning_rate: 5.0000e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9633 - loss: 0.2169\n",
      "Epoch 36: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9632 - loss: 0.2168 - val_accuracy: 0.9875 - val_loss: 0.0280 - learning_rate: 5.0000e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9585 - loss: 0.2064\n",
      "Epoch 37: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9585 - loss: 0.2070 - val_accuracy: 0.9958 - val_loss: 0.0357 - learning_rate: 5.0000e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9654 - loss: 0.2113\n",
      "Epoch 38: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9654 - loss: 0.2115 - val_accuracy: 1.0000 - val_loss: 0.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9711 - loss: 0.1712\n",
      "Epoch 39: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9712 - loss: 0.1708 - val_accuracy: 1.0000 - val_loss: 0.0138 - learning_rate: 5.0000e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9747 - loss: 0.1675\n",
      "Epoch 40: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9748 - loss: 0.1666 - val_accuracy: 0.9917 - val_loss: 0.0140 - learning_rate: 5.0000e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9640 - loss: 0.2618\n",
      "Epoch 41: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9642 - loss: 0.2606 - val_accuracy: 0.9958 - val_loss: 0.0164 - learning_rate: 5.0000e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9692 - loss: 0.1665\n",
      "Epoch 42: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9694 - loss: 0.1665 - val_accuracy: 1.0000 - val_loss: 0.0086 - learning_rate: 5.0000e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9841 - loss: 0.1273\n",
      "Epoch 43: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9840 - loss: 0.1269 - val_accuracy: 1.0000 - val_loss: 0.0036 - learning_rate: 5.0000e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m28/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9880 - loss: 0.1090\n",
      "Epoch 44: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9877 - loss: 0.1105 - val_accuracy: 1.0000 - val_loss: 0.0021 - learning_rate: 5.0000e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9767 - loss: 0.1372\n",
      "Epoch 45: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9767 - loss: 0.1367 - val_accuracy: 0.9917 - val_loss: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9735 - loss: 0.1683\n",
      "Epoch 46: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9736 - loss: 0.1678 - val_accuracy: 1.0000 - val_loss: 0.0077 - learning_rate: 5.0000e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9709 - loss: 0.1315\n",
      "Epoch 47: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9711 - loss: 0.1313 - val_accuracy: 0.9917 - val_loss: 0.0141 - learning_rate: 5.0000e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9834 - loss: 0.1061\n",
      "Epoch 48: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9836 - loss: 0.1066 - val_accuracy: 0.9958 - val_loss: 0.0088 - learning_rate: 5.0000e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9900 - loss: 0.0787\n",
      "Epoch 49: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9899 - loss: 0.0790 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 5.0000e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9916 - loss: 0.0578\n",
      "Epoch 50: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9916 - loss: 0.0586 - val_accuracy: 0.9875 - val_loss: 0.0469 - learning_rate: 5.0000e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9851 - loss: 0.0893\n",
      "Epoch 51: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9850 - loss: 0.0898 - val_accuracy: 1.0000 - val_loss: 0.0016 - learning_rate: 5.0000e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0463\n",
      "Epoch 52: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9960 - loss: 0.0470 - val_accuracy: 1.0000 - val_loss: 0.0020 - learning_rate: 5.0000e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.0618\n",
      "Epoch 53: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9936 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 7.1486e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9907 - loss: 0.0615\n",
      "Epoch 54: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9907 - loss: 0.0618 - val_accuracy: 1.0000 - val_loss: 7.0674e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9845 - loss: 0.1229\n",
      "Epoch 55: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9846 - loss: 0.1222 - val_accuracy: 1.0000 - val_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9888 - loss: 0.0929\n",
      "Epoch 56: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9887 - loss: 0.0934 - val_accuracy: 0.9958 - val_loss: 0.0086 - learning_rate: 5.0000e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9930 - loss: 0.0559\n",
      "Epoch 57: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9929 - loss: 0.0569 - val_accuracy: 1.0000 - val_loss: 9.0588e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9933 - loss: 0.0960\n",
      "Epoch 58: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9933 - loss: 0.0950 - val_accuracy: 1.0000 - val_loss: 7.9624e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9952 - loss: 0.0823\n",
      "Epoch 59: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9951 - loss: 0.0823 - val_accuracy: 1.0000 - val_loss: 7.5025e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9960 - loss: 0.0339\n",
      "Epoch 60: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9961 - loss: 0.0338 - val_accuracy: 1.0000 - val_loss: 5.9254e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9795 - loss: 0.0947\n",
      "Epoch 61: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9797 - loss: 0.0949 - val_accuracy: 1.0000 - val_loss: 7.7732e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9801 - loss: 0.1327\n",
      "Epoch 62: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9805 - loss: 0.1305 - val_accuracy: 0.9833 - val_loss: 0.0611 - learning_rate: 5.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m29/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9820 - loss: 0.2101\n",
      "Epoch 63: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9824 - loss: 0.2042 - val_accuracy: 1.0000 - val_loss: 6.6981e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 63: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\n",
      "Fold 5 Classification Report:\n",
      "Fold 5 Accuracy: 1.0000\n",
      "\n",
      "🏆 Best model from fold 1 with accuracy: 1.0000\n",
      "\n",
      "🔄 Training final model on entire dataset...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elroy\\gesture_env\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 98 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9723 - loss: 0.1398\n",
      "Epoch 1: loss improved from inf to 0.13837, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9725 - loss: 0.1398 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9790 - loss: 0.1327\n",
      "Epoch 2: loss improved from 0.13837 to 0.11396, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9792 - loss: 0.1318 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9818 - loss: 0.1553\n",
      "Epoch 3: loss did not improve from 0.11396\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9819 - loss: 0.1549 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9812 - loss: 0.1118\n",
      "Epoch 4: loss improved from 0.11396 to 0.11167, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9813 - loss: 0.1118 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9782 - loss: 0.1590\n",
      "Epoch 5: loss did not improve from 0.11167\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9783 - loss: 0.1586 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9953 - loss: 0.0816\n",
      "Epoch 6: loss improved from 0.11167 to 0.10096, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9951 - loss: 0.0826 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9870 - loss: 0.0732\n",
      "Epoch 7: loss improved from 0.10096 to 0.07072, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9870 - loss: 0.0732 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9910 - loss: 0.0767\n",
      "Epoch 8: loss did not improve from 0.07072\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9910 - loss: 0.0769 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9889 - loss: 0.1359\n",
      "Epoch 9: loss did not improve from 0.07072\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9890 - loss: 0.1344 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9875 - loss: 0.0660\n",
      "Epoch 10: loss did not improve from 0.07072\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9875 - loss: 0.0666 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9839 - loss: 0.0959\n",
      "Epoch 11: loss improved from 0.07072 to 0.06912, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9841 - loss: 0.0952 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9838 - loss: 0.1367\n",
      "Epoch 12: loss did not improve from 0.06912\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9841 - loss: 0.1335 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0267\n",
      "Epoch 13: loss improved from 0.06912 to 0.02449, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9996 - loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9978 - loss: 0.0277\n",
      "Epoch 14: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0276 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9973 - loss: 0.0284\n",
      "Epoch 15: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9972 - loss: 0.0288 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9762 - loss: 0.1662\n",
      "Epoch 16: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9765 - loss: 0.1636 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9865 - loss: 0.0640\n",
      "Epoch 17: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9868 - loss: 0.0627 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9890 - loss: 0.0772\n",
      "Epoch 18: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9890 - loss: 0.0774 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9912 - loss: 0.0535\n",
      "Epoch 19: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9912 - loss: 0.0535 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9899 - loss: 0.0447\n",
      "Epoch 20: loss did not improve from 0.02449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9900 - loss: 0.0442 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9965 - loss: 0.0180\n",
      "Epoch 21: loss improved from 0.02449 to 0.02001, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9965 - loss: 0.0180 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0209\n",
      "Epoch 22: loss did not improve from 0.02001\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0212 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9976 - loss: 0.0318\n",
      "Epoch 23: loss did not improve from 0.02001\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9975 - loss: 0.0321 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9978 - loss: 0.0254\n",
      "Epoch 24: loss did not improve from 0.02001\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0254 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9866 - loss: 0.0705\n",
      "Epoch 25: loss did not improve from 0.02001\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9870 - loss: 0.0695 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0131\n",
      "Epoch 26: loss improved from 0.02001 to 0.01440, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0132 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0392\n",
      "Epoch 27: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0386 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9980 - loss: 0.0307\n",
      "Epoch 28: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0313 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9932 - loss: 0.0571\n",
      "Epoch 29: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9932 - loss: 0.0568 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9970 - loss: 0.0245\n",
      "Epoch 30: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9969 - loss: 0.0248 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9926 - loss: 0.1115\n",
      "Epoch 31: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9926 - loss: 0.1114 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9916 - loss: 0.0635\n",
      "Epoch 32: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9916 - loss: 0.0634 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9941 - loss: 0.0513\n",
      "Epoch 33: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9940 - loss: 0.0517 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9898 - loss: 0.0730\n",
      "Epoch 34: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9900 - loss: 0.0719 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0155\n",
      "Epoch 35: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9949 - loss: 0.0320\n",
      "Epoch 36: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9949 - loss: 0.0318 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9994 - loss: 0.0167\n",
      "Epoch 37: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9994 - loss: 0.0169 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9907 - loss: 0.0476\n",
      "Epoch 38: loss did not improve from 0.01440\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9907 - loss: 0.0475 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9999 - loss: 0.0105\n",
      "Epoch 39: loss improved from 0.01440 to 0.01165, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9971 - loss: 0.0361\n",
      "Epoch 40: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9970 - loss: 0.0368 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9943 - loss: 0.0620\n",
      "Epoch 41: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9943 - loss: 0.0608 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9921 - loss: 0.0394\n",
      "Epoch 42: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9921 - loss: 0.0394 - learning_rate: 5.0000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9956 - loss: 0.0670\n",
      "Epoch 43: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9957 - loss: 0.0663 - learning_rate: 5.0000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0171\n",
      "Epoch 44: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0172 - learning_rate: 5.0000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9928 - loss: 0.0238\n",
      "Epoch 45: loss did not improve from 0.01165\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9930 - loss: 0.0235 - learning_rate: 5.0000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0074\n",
      "Epoch 46: loss improved from 0.01165 to 0.00945, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9977 - loss: 0.0074 - learning_rate: 5.0000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9989 - loss: 0.0275\n",
      "Epoch 47: loss did not improve from 0.00945\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0272 - learning_rate: 5.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0105\n",
      "Epoch 48: loss improved from 0.00945 to 0.00851, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0056\n",
      "Epoch 49: loss improved from 0.00851 to 0.00524, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0055 - learning_rate: 5.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 50: loss did not improve from 0.00524\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0056\n",
      "Epoch 51: loss did not improve from 0.00524\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 52: loss improved from 0.00524 to 0.00438, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9934 - loss: 0.0528\n",
      "Epoch 53: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9935 - loss: 0.0522 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9996 - loss: 0.0110\n",
      "Epoch 54: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9995 - loss: 0.0111 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9919 - loss: 0.0858\n",
      "Epoch 55: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9919 - loss: 0.0862 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9911 - loss: 0.0798\n",
      "Epoch 56: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9911 - loss: 0.0792 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9912 - loss: 0.0388\n",
      "Epoch 57: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9912 - loss: 0.0389 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0474\n",
      "Epoch 58: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9938 - loss: 0.0471 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9874 - loss: 0.0728\n",
      "Epoch 59: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9875 - loss: 0.0723 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9971 - loss: 0.0145\n",
      "Epoch 60: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9971 - loss: 0.0146 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0139\n",
      "Epoch 61: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0140 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0174\n",
      "Epoch 62: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0177 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9880 - loss: 0.0619\n",
      "Epoch 63: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9883 - loss: 0.0607 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0103\n",
      "Epoch 64: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0104 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9971 - loss: 0.0386\n",
      "Epoch 65: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9971 - loss: 0.0385 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9993 - loss: 0.0133\n",
      "Epoch 66: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9992 - loss: 0.0138 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9977 - loss: 0.0143\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9976 - loss: 0.0143 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9963 - loss: 0.0464\n",
      "Epoch 68: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9961 - loss: 0.0463 - learning_rate: 2.5000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9914 - loss: 0.0451\n",
      "Epoch 69: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9916 - loss: 0.0444 - learning_rate: 2.5000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9918 - loss: 0.0265\n",
      "Epoch 70: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.0262 - learning_rate: 2.5000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9958 - loss: 0.0240\n",
      "Epoch 71: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9958 - loss: 0.0247 - learning_rate: 2.5000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9994 - loss: 0.0047\n",
      "Epoch 72: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0047 - learning_rate: 2.5000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0043\n",
      "Epoch 73: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0044 - learning_rate: 2.5000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0067\n",
      "Epoch 74: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0066 - learning_rate: 2.5000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9998 - loss: 0.0039\n",
      "Epoch 75: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.0039 - learning_rate: 2.5000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0098\n",
      "Epoch 76: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0096 - learning_rate: 2.5000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9984 - loss: 0.0095\n",
      "Epoch 77: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9984 - loss: 0.0096 - learning_rate: 2.5000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0062\n",
      "Epoch 78: loss did not improve from 0.00438\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0062 - learning_rate: 2.5000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0032\n",
      "Epoch 79: loss improved from 0.00438 to 0.00365, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0032 - learning_rate: 2.5000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9993 - loss: 0.0092\n",
      "Epoch 80: loss did not improve from 0.00365\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0092 - learning_rate: 2.5000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9946 - loss: 0.0207\n",
      "Epoch 81: loss did not improve from 0.00365\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9948 - loss: 0.0201 - learning_rate: 2.5000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 82: loss improved from 0.00365 to 0.00363, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m36/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.0044\n",
      "Epoch 83: loss did not improve from 0.00363\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9997 - loss: 0.0044 - learning_rate: 2.5000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0034\n",
      "Epoch 84: loss did not improve from 0.00363\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0035 - learning_rate: 2.5000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 85: loss improved from 0.00363 to 0.00345, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0030 - learning_rate: 2.5000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9998 - loss: 0.0031\n",
      "Epoch 86: loss improved from 0.00345 to 0.00311, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9997 - loss: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0070\n",
      "Epoch 87: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9988 - loss: 0.0070 - learning_rate: 2.5000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9976 - loss: 0.0571\n",
      "Epoch 88: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0569 - learning_rate: 2.5000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m36/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9993 - loss: 0.0141\n",
      "Epoch 89: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0151 - learning_rate: 2.5000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9999 - loss: 0.0044\n",
      "Epoch 90: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0099\n",
      "Epoch 91: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0097 - learning_rate: 2.5000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9998 - loss: 0.0052\n",
      "Epoch 92: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0052 - learning_rate: 2.5000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0041\n",
      "Epoch 93: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0042 - learning_rate: 2.5000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0077\n",
      "Epoch 94: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9993 - loss: 0.0077 - learning_rate: 2.5000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0060\n",
      "Epoch 95: loss did not improve from 0.00311\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0069 - learning_rate: 2.5000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0029\n",
      "Epoch 96: loss improved from 0.00311 to 0.00293, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0029 - learning_rate: 2.5000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0053\n",
      "Epoch 97: loss did not improve from 0.00293\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9977 - loss: 0.0053 - learning_rate: 2.5000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0210\n",
      "Epoch 98: loss did not improve from 0.00293\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9991 - loss: 0.0213 - learning_rate: 2.5000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0027\n",
      "Epoch 99: loss did not improve from 0.00293\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0028 - learning_rate: 2.5000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m37/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0065\n",
      "Epoch 100: loss did not improve from 0.00293\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9994 - loss: 0.0066 - learning_rate: 2.5000e-04\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 1.3229e-04\n",
      "\n",
      "Final model accuracy on entire dataset: 100.00%\n",
      "✅ Saved labels.npy\n",
      "🔄 Converting to TFLite...\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\elroy\\AppData\\Local\\Temp\\tmpo4il44uq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\elroy\\AppData\\Local\\Temp\\tmpo4il44uq\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\elroy\\AppData\\Local\\Temp\\tmpo4il44uq'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 60, 63), dtype=tf.float32, name='sequence_input')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2860628421168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628418000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140512608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140513312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140506096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140502928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628421696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628423104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628416064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628421344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628413952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628410784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628412192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628412720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140507152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140509088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140499584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2859140506624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628505904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628505200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628501152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628505376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628506960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628507840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628562288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628561056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628499040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628558064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628564752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628693008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628690368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628563168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628690544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628694240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628703920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628700048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628703744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628699344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628698992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628775104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628775808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628772992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628775984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628778800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628784960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628781792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628785136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628786896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628782320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628781088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628782144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628859312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628859488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628858784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628856672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628855440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628867936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2860628864768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ Saved gesture_model.tflite\n",
      "🎉 Training complete. Use `gesture_model.tflite` and `labels.npy` for inference.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional, Input\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Concatenate, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, LayerNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.utils import resample, class_weight\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# ── CONFIG ─────────────────────────────\n",
    "SEQUENCE_LENGTH = 60\n",
    "LANDMARKS = 63  # Total landmarks: 21 hand landmarks × 3 coordinates (x, y, z)\n",
    "GESTURE_LABELS = [\"swipe_left\", \"swipe_right\", \"swipe_up\", \"swipe_down\", \"screenshot\", \"drop\", \"like\", \"dislike\", \"sos\", \"peace\"]\n",
    "DATASET_DIR = \"dataset\"\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "AUGMENTATION_NOISE = 0.01\n",
    "NUM_CLASSES = len(GESTURE_LABELS)\n",
    "\n",
    "# Define static and dynamic gestures\n",
    "STATIC_GESTURES = [\"like\", \"dislike\", \"peace\"]\n",
    "DYNAMIC_GESTURES = [g for g in GESTURE_LABELS if g not in STATIC_GESTURES]\n",
    "\n",
    "# ── LOAD DATA FROM CSV FILES ───────────\n",
    "print(\"Loading data...\")\n",
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "# Modified loading code to handle the structure created by the recording script\n",
    "for label_idx, gesture in enumerate(GESTURE_LABELS):\n",
    "    # Check both root directory and type-specific subdirectories\n",
    "    possible_dirs = [\n",
    "        os.path.join(DATASET_DIR, gesture),  # Direct gesture folder\n",
    "        os.path.join(DATASET_DIR, \"static\", gesture),  # Static gestures\n",
    "        os.path.join(DATASET_DIR, \"dynamic\", gesture)  # Dynamic gestures\n",
    "    ]\n",
    "    \n",
    "    for gesture_dir in possible_dirs:\n",
    "        if not os.path.exists(gesture_dir):\n",
    "            continue\n",
    "            \n",
    "        gesture_files = [f for f in os.listdir(gesture_dir) if f.endswith('.csv')]\n",
    "        print(f\"Found {len(gesture_files)} sequences for gesture '{gesture}' in {gesture_dir}\")\n",
    "        \n",
    "        for file_name in gesture_files:\n",
    "            file_path = os.path.join(gesture_dir, file_name)\n",
    "            try:\n",
    "                sequence = pd.read_csv(file_path, header=None).values\n",
    "                if sequence.shape != (SEQUENCE_LENGTH, LANDMARKS):\n",
    "                    print(f\"⚠️ Skipping {file_path}: Expected shape {(SEQUENCE_LENGTH, LANDMARKS)}, got {sequence.shape}\")\n",
    "                    continue\n",
    "                X_data.append(sequence)\n",
    "                y_labels.append(label_idx)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Error loading {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "if not X_data:\n",
    "    print(\"❌ No valid data found. Please check your dataset directories.\")\n",
    "    exit()\n",
    "\n",
    "X_data = np.array(X_data, dtype=np.float32)\n",
    "y_labels = np.array(y_labels)\n",
    "\n",
    "# Update GESTURE_LABELS based on loaded data\n",
    "loaded_labels = np.unique(y_labels)\n",
    "if len(loaded_labels) != len(GESTURE_LABELS):\n",
    "    print(f\"⚠️ Mismatch: Expected {len(GESTURE_LABELS)} gestures, but only {len(loaded_labels)} were loaded.\")\n",
    "    missing_labels = set(range(len(GESTURE_LABELS))) - set(loaded_labels)\n",
    "    missing_gestures = [GESTURE_LABELS[idx] for idx in missing_labels]\n",
    "    print(f\"Missing gestures: {missing_gestures}\")\n",
    "    GESTURE_LABELS = [GESTURE_LABELS[idx] for idx in sorted(loaded_labels)]\n",
    "    STATIC_GESTURES = [g for g in STATIC_GESTURES if g in GESTURE_LABELS]\n",
    "    DYNAMIC_GESTURES = [g for g in DYNAMIC_GESTURES if g in GESTURE_LABELS]\n",
    "    NUM_CLASSES = len(GESTURE_LABELS)\n",
    "    print(f\"Updated GESTURE_LABELS: {GESTURE_LABELS}\")\n",
    "\n",
    "# Print class distribution before preprocessing\n",
    "unique, counts = np.unique(y_labels, return_counts=True)\n",
    "print(\"\\n--- Initial Class Distribution ---\")\n",
    "for i, (label_idx, count) in enumerate(zip(unique, counts)):\n",
    "    print(f\"{GESTURE_LABELS[label_idx]}: {count} samples\")\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "# ── DATA PREPROCESSING ─────────────────\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Normalize sequences by subtracting the first frame\n",
    "X_data_norm = np.array([seq - seq[0] for seq in X_data])\n",
    "\n",
    "# Extract velocity features (temporal derivatives)\n",
    "X_velocity = np.zeros_like(X_data_norm)\n",
    "for i in range(len(X_data_norm)):\n",
    "    X_velocity[i, 1:, :] = X_data_norm[i, 1:, :] - X_data_norm[i, :-1, :]\n",
    "    X_velocity[i, 0, :] = 0  # First frame has zero velocity\n",
    "\n",
    "# Compute magnitude of movement for each landmark\n",
    "X_magnitude = np.zeros((X_data_norm.shape[0], X_data_norm.shape[1], X_data_norm.shape[2]//3))\n",
    "for i in range(len(X_data_norm)):\n",
    "    for j in range(0, X_data_norm.shape[2], 3):\n",
    "        if j+2 < X_data_norm.shape[2]:  # Ensure we have x, y, z\n",
    "            x = X_data_norm[i, :, j]\n",
    "            y = X_data_norm[i, :, j+1]\n",
    "            z = X_data_norm[i, :, j+2] if (j+2) < X_data_norm.shape[2] else np.zeros_like(x)\n",
    "            X_magnitude[i, :, j//3] = np.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "# For static gestures, compute the mean pose over the sequence\n",
    "X_data_static = np.zeros_like(X_data_norm)\n",
    "for i, label in enumerate(y_labels):\n",
    "    gesture = GESTURE_LABELS[label]\n",
    "    if gesture in STATIC_GESTURES:\n",
    "        # For static gestures, take the average of frames 20-40 (middle of sequence)\n",
    "        middle_frames = X_data_norm[i, 20:40, :]\n",
    "        mean_pose = np.mean(middle_frames, axis=0, keepdims=True)\n",
    "        X_data_static[i] = np.repeat(mean_pose, SEQUENCE_LENGTH, axis=0)\n",
    "    else:\n",
    "        X_data_static[i] = X_data_norm[i]\n",
    "\n",
    "# ── ENHANCED AUGMENTATION ───────────────\n",
    "def augment_data(X, y, noise_level=AUGMENTATION_NOISE, time_warp_factor=0.2):\n",
    "    # Add noise\n",
    "    X_augmented = X.copy()\n",
    "    noise = np.random.uniform(-noise_level, noise_level, X.shape)\n",
    "    X_augmented += noise\n",
    "    \n",
    "    # Time warping (speed variations)\n",
    "    X_time_warped = []\n",
    "    y_time_warped = []\n",
    "    \n",
    "    for i, sequence in enumerate(X):\n",
    "        # Only apply time warping to dynamic gestures\n",
    "        if GESTURE_LABELS[y[i]] in DYNAMIC_GESTURES:\n",
    "            # Slow down\n",
    "            slow_factor = 1 - np.random.uniform(0, time_warp_factor)\n",
    "            slow_length = min(int(SEQUENCE_LENGTH * slow_factor), SEQUENCE_LENGTH-1)\n",
    "            indices = np.linspace(0, slow_length-1, SEQUENCE_LENGTH).astype(int)\n",
    "            slow_sequence = sequence[indices]\n",
    "            X_time_warped.append(slow_sequence)\n",
    "            y_time_warped.append(y[i])\n",
    "            \n",
    "            # Speed up\n",
    "            fast_factor = 1 + np.random.uniform(0, time_warp_factor)\n",
    "            fast_length = min(int(SEQUENCE_LENGTH * fast_factor), SEQUENCE_LENGTH)\n",
    "            if fast_length > SEQUENCE_LENGTH:\n",
    "                indices = np.linspace(0, SEQUENCE_LENGTH-1, fast_length).astype(int)\n",
    "                fast_sequence = sequence[indices[:SEQUENCE_LENGTH]]\n",
    "            else:\n",
    "                indices = np.linspace(0, fast_length-1, SEQUENCE_LENGTH).astype(int)\n",
    "                fast_sequence = np.zeros_like(sequence)\n",
    "                fast_sequence[:fast_length] = sequence[indices]\n",
    "                fast_sequence[fast_length:] = sequence[-1]  # Pad with last frame\n",
    "            X_time_warped.append(fast_sequence)\n",
    "            y_time_warped.append(y[i])\n",
    "    \n",
    "    if X_time_warped:\n",
    "        X_time_warped = np.array(X_time_warped)\n",
    "        y_time_warped = np.array(y_time_warped)\n",
    "        X_augmented = np.vstack([X_augmented, X_time_warped])\n",
    "        y = np.hstack([y, y_time_warped])\n",
    "    \n",
    "    return X_augmented, y\n",
    "\n",
    "# ── BALANCE DATASET ────────────────────\n",
    "print(\"\\n--- Balancing dataset ---\")\n",
    "unique, counts = np.unique(y_labels, return_counts=True)\n",
    "max_samples = max(counts)\n",
    "X_balanced = []\n",
    "y_balanced = []\n",
    "\n",
    "for label_idx in unique:\n",
    "    X_class = X_data_norm[y_labels == label_idx]\n",
    "    y_class = y_labels[y_labels == label_idx]\n",
    "    if len(X_class) < max_samples:\n",
    "        X_class_resampled, y_class_resampled = resample(\n",
    "            X_class, y_class,\n",
    "            replace=True,\n",
    "            n_samples=max_samples,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "        X_balanced.append(X_class_resampled)\n",
    "        y_balanced.append(y_class_resampled)\n",
    "    else:\n",
    "        X_balanced.append(X_class)\n",
    "        y_balanced.append(y_class)\n",
    "\n",
    "X_data_norm = np.vstack(X_balanced)\n",
    "y_labels_balanced = np.hstack(y_balanced)\n",
    "\n",
    "# Apply augmentation to balanced dataset\n",
    "X_data_norm, y_labels_balanced = augment_data(X_data_norm, y_labels_balanced)\n",
    "\n",
    "# Print new class distribution\n",
    "unique, counts = np.unique(y_labels_balanced, return_counts=True)\n",
    "print(\"\\n--- Class Distribution After Balancing and Augmentation ---\")\n",
    "for i, (label_idx, count) in enumerate(zip(unique, counts)):\n",
    "    print(f\"{GESTURE_LABELS[label_idx]}: {count} samples\")\n",
    "print(\"-------------------------\\n\")\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_data = tf.keras.utils.to_categorical(y_labels_balanced, NUM_CLASSES)\n",
    "\n",
    "print(f\"✅ Loaded and processed {len(X_data_norm)} sequences with shape {X_data_norm.shape}\")\n",
    "\n",
    "# ── ADVANCED MODEL ARCHITECTURE ─────────\n",
    "print(\"Building enhanced gesture recognition model...\")\n",
    "\n",
    "def create_attention_layer(query, value, key=None):\n",
    "    if key is None:\n",
    "        key = value\n",
    "    # Multihead attention layer\n",
    "    return tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=4, key_dim=32\n",
    "    )(query=query, value=value, key=key)\n",
    "\n",
    "def create_enhanced_model():\n",
    "    # Main sequence input\n",
    "    input_seq = Input(shape=(SEQUENCE_LENGTH, LANDMARKS), name='sequence_input')\n",
    "    \n",
    "    # === SPATIAL FEATURE EXTRACTION ===\n",
    "    # CNN Block 1: Capture spatial patterns with different kernel sizes\n",
    "    conv1 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(input_seq)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = SpatialDropout1D(0.3)(conv1)\n",
    "    \n",
    "    conv2 = Conv1D(64, kernel_size=5, padding='same', activation='relu')(input_seq)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = SpatialDropout1D(0.3)(conv2)\n",
    "    \n",
    "    conv3 = Conv1D(64, kernel_size=7, padding='same', activation='relu')(input_seq)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = SpatialDropout1D(0.3)(conv3)\n",
    "    \n",
    "    # Combine CNN features\n",
    "    cnn_features = Concatenate()([conv1, conv2, conv3])\n",
    "    cnn_features = MaxPooling1D(pool_size=2)(cnn_features)\n",
    "    \n",
    "    # === TEMPORAL FEATURE EXTRACTION ===\n",
    "    # LSTM Block: Capture temporal relationships\n",
    "    lstm = Bidirectional(LSTM(128, return_sequences=True))(cnn_features)\n",
    "    lstm = LayerNormalization()(lstm)\n",
    "    lstm = SpatialDropout1D(0.4)(lstm)\n",
    "    \n",
    "    lstm = Bidirectional(LSTM(64, return_sequences=True))(lstm)\n",
    "    lstm = LayerNormalization()(lstm)\n",
    "    lstm = SpatialDropout1D(0.3)(lstm)\n",
    "    \n",
    "    # Self-attention mechanism to focus on important parts of the sequence\n",
    "    attention_output = create_attention_layer(lstm, lstm)\n",
    "    attention_output = LayerNormalization()(attention_output)\n",
    "    \n",
    "    # Global feature extraction\n",
    "    global_max = GlobalAveragePooling1D()(attention_output)\n",
    "    \n",
    "    # === FINAL CLASSIFICATION LAYERS ===\n",
    "    dense = Dense(128, activation='relu')(global_max)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.5)(dense)\n",
    "    \n",
    "    dense = Dense(64, activation='relu')(dense)\n",
    "    dense = BatchNormalization()(dense)\n",
    "    dense = Dropout(0.4)(dense)\n",
    "    \n",
    "    output = Dense(NUM_CLASSES, activation='softmax')(dense)\n",
    "    \n",
    "    model = Model(inputs=input_seq, outputs=output)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.0005)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ── K-FOLD CROSS VALIDATION ───────────\n",
    "def perform_kfold_training(X, y, n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_SEED)\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X)):\n",
    "        print(f\"\\n--- Training Fold {fold+1}/{n_splits} ---\")\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Compute class weights for this fold\n",
    "        y_train_classes = np.argmax(y_train_fold, axis=1)\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(y_train_classes),\n",
    "            y=y_train_classes\n",
    "        )\n",
    "        class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "        \n",
    "        # Create and train model for this fold\n",
    "        model = create_enhanced_model()\n",
    "        if fold == 0:  # Only print summary for first fold\n",
    "            model.summary()\n",
    "        \n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=30,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=15,\n",
    "            min_lr=0.0000001,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        model_checkpoint = ModelCheckpoint(\n",
    "            filepath=f'best_model_fold{fold+1}.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            epochs=150,\n",
    "            batch_size=32,\n",
    "            callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "            class_weight=class_weights_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate fold performance\n",
    "        y_val_pred = model.predict(X_val_fold, verbose=0)\n",
    "        y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "        y_val_true_classes = np.argmax(y_val_fold, axis=1)\n",
    "        \n",
    "        print(f\"\\nFold {fold+1} Classification Report:\")\n",
    "        report = classification_report(\n",
    "            y_val_true_classes, \n",
    "            y_val_pred_classes, \n",
    "            target_names=GESTURE_LABELS, \n",
    "            output_dict=True\n",
    "        )\n",
    "        fold_results.append({\n",
    "            'model': model,\n",
    "            'history': history,\n",
    "            'report': report,\n",
    "            'accuracy': report['accuracy']\n",
    "        })\n",
    "        \n",
    "        print(f\"Fold {fold+1} Accuracy: {report['accuracy']:.4f}\")\n",
    "        \n",
    "        # Plot confusion matrix for this fold\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        cm = confusion_matrix(y_val_true_classes, y_val_pred_classes)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=GESTURE_LABELS, yticklabels=GESTURE_LABELS)\n",
    "        plt.title(f'Confusion Matrix - Fold {fold+1}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'confusion_matrix_fold{fold+1}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    return fold_results\n",
    "\n",
    "# ── TRAIN WITH CROSS-VALIDATION ─────────────────\n",
    "print(\"\\n🧠 Starting k-fold cross-validation training...\")\n",
    "# Create train/validation split for final evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_data_norm, y_data,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=np.argmax(y_data, axis=1)\n",
    ")\n",
    "\n",
    "# Run a quick sanity check\n",
    "print(f\"\\nSanity check - Training split shape: {X_train.shape}\")\n",
    "print(f\"Sanity check - Validation split shape: {X_val.shape}\")\n",
    "\n",
    "if NUM_CLASSES == 0 or X_data_norm.shape[0] == 0:\n",
    "    print(\"❌ Error: No valid data for training. Check your dataset directories.\")\n",
    "    exit()\n",
    "\n",
    "# First run k-fold cross-validation\n",
    "fold_results = perform_kfold_training(X_data_norm, y_data, n_splits=5)\n",
    "\n",
    "# Find best performing fold model\n",
    "best_fold = max(range(len(fold_results)), key=lambda i: fold_results[i]['accuracy'])\n",
    "best_model = fold_results[best_fold]['model']\n",
    "print(f\"\\n🏆 Best model from fold {best_fold+1} with accuracy: {fold_results[best_fold]['accuracy']:.4f}\")\n",
    "\n",
    "# ── TRAIN FINAL MODEL ON ENTIRE DATASET ─\n",
    "print(\"\\n🔄 Training final model on entire dataset...\")\n",
    "final_model = create_enhanced_model()\n",
    "\n",
    "# Use parameters from the best fold model\n",
    "best_model.save_weights('best_fold_weights.weights.h5')\n",
    "final_model.load_weights('best_fold_weights.weights.h5')\n",
    "\n",
    "# Further train on entire dataset\n",
    "y_classes = np.argmax(y_data, axis=1)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_classes),\n",
    "    y=y_classes\n",
    ")\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Callbacks for final model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=30,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='loss',\n",
    "    factor=0.5,\n",
    "    patience=15,\n",
    "    min_lr=0.0000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.h5',\n",
    "    monitor='loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "final_history = final_model.fit(\n",
    "    X_data_norm, y_data,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "    class_weight=class_weights_dict,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the entire dataset\n",
    "loss, accuracy = final_model.evaluate(X_data_norm, y_data, verbose=1)\n",
    "print(f\"\\nFinal model accuracy on entire dataset: {accuracy*100:.2f}%\")\n",
    "\n",
    "# ── SAVE LABELS ────────────────────────\n",
    "np.save(\"labels.npy\", np.array(GESTURE_LABELS))\n",
    "print(\"✅ Saved labels.npy\")\n",
    "\n",
    "# ── CONVERT TO TFLITE ──────────────────\n",
    "print(\"🔄 Converting to TFLite...\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# ── SAVE TFLITE MODEL ──────────────────\n",
    "with open(\"gesture_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "print(\"✅ Saved gesture_model.tflite\")\n",
    "\n",
    "# ── PLOT TRAINING HISTORY ──────────────\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Plot accuracy and loss for each fold\n",
    "plt.subplot(2, 1, 1)\n",
    "for i, result in enumerate(fold_results):\n",
    "    plt.plot(result['history'].history['accuracy'], label=f'Fold {i+1} Train')\n",
    "    plt.plot(result['history'].history['val_accuracy'], label=f'Fold {i+1} Val', linestyle='--')\n",
    "plt.title('K-Fold Cross-Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "for i, result in enumerate(fold_results):\n",
    "    plt.plot(result['history'].history['loss'], label=f'Fold {i+1} Train')\n",
    "    plt.plot(result['history'].history['val_loss'], label=f'Fold {i+1} Val', linestyle='--')\n",
    "plt.title('K-Fold Cross-Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kfold_training_history.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"🎉 Training complete. Use `gesture_model.tflite` and `labels.npy` for inference.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640179bd-e738-497d-b09d-a5a8a9705f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "🖐 Gesture Env",
   "language": "python",
   "name": "gesture_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
