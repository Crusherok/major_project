{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a65277d-e94a-4887-a9cd-4458f74a240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the dataset for recording DYNAMIC GESTURES\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# ‚îÄ‚îÄ DETECT JUPYTER ENVIRONMENT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        get_ipython()\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "# ‚îÄ‚îÄ CONFIG FOR JUPYTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Set these manually if running in Jupyter Notebook\n",
    "GESTURE_NAME = \"sos\"  # Change this for each gesture\n",
    "MAX_RECORDINGS = 5  # Number of gesture performances\n",
    "NUM_VARIATIONS = 10  # Total files per performance (1 original + 9 augmented)\n",
    "\n",
    "# ‚îÄ‚îÄ PARSE ARGUMENTS FOR COMMAND LINE ‚îÄ‚îÄ‚îÄ\n",
    "if not is_jupyter():\n",
    "    parser = argparse.ArgumentParser(description=\"Record gesture sequences for dataset creation.\")\n",
    "    parser.add_argument(\"--gesture\", type=str, default=\"dislike\", help=\"Name of the gesture to record (e.g., swipe_right, like).\")\n",
    "    parser.add_argument(\"--samples\", type=int, default=5, help=\"Number of gesture performances to record.\")\n",
    "    parser.add_argument(\"--variations\", type=int, default=10, help=\"Number of files to save per performance (1 original + augmented).\")\n",
    "    args = parser.parse_args()\n",
    "    GESTURE_NAME = args.gesture\n",
    "    MAX_RECORDINGS = args.samples\n",
    "    NUM_VARIATIONS = args.variations\n",
    "\n",
    "# ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SEQUENCE_LENGTH = 60\n",
    "SAVE_DIR = f\"dataset/{GESTURE_NAME}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "MIN_VALID_FRAMES = 50\n",
    "MOVEMENT_THRESHOLD = 0.1\n",
    "AUGMENTATION_NOISE = 0.02\n",
    "\n",
    "# ‚îÄ‚îÄ INIT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                       min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "buffer = deque(maxlen=SEQUENCE_LENGTH)\n",
    "recording = False\n",
    "sample_count = 0\n",
    "valid_frames = 0\n",
    "\n",
    "# FPS counter\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "def augment_sequence(sequence, noise_level=AUGMENTATION_NOISE):\n",
    "    \"\"\"Generate an augmented version of the sequence by adding noise.\"\"\"\n",
    "    augmented = sequence.copy()\n",
    "    noise = np.random.uniform(-noise_level, noise_level, sequence.shape)\n",
    "    augmented += noise\n",
    "    augmented[:, ::3] = np.clip(augmented[:, ::3], 0, 1)  # x\n",
    "    augmented[:, 1::3] = np.clip(augmented[:, 1::3], 0, 1)  # y\n",
    "    return augmented\n",
    "\n",
    "def check_movement(sequence, threshold=MOVEMENT_THRESHOLD):\n",
    "    \"\"\"Check if the sequence has significant movement (for dynamic gestures).\"\"\"\n",
    "    sequence = np.array(sequence)\n",
    "    x_coords = sequence[:, ::3]\n",
    "    x_range = np.ptp(x_coords, axis=0).max()\n",
    "    y_coords = sequence[:, 1::3]\n",
    "    y_range = np.ptp(y_coords, axis=0).max()\n",
    "    return max(x_range, y_range) >= threshold\n",
    "\n",
    "print(f\"üì∏ Recording {MAX_RECORDINGS} performances for gesture: {GESTURE_NAME}\")\n",
    "print(f\"Each performance will save {NUM_VARIATIONS} files (1 original + {NUM_VARIATIONS-1} augmented).\")\n",
    "print(\"üì∏ Press 's' to start recording a gesture.\")\n",
    "print(\"‚ùå Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if time.time() - start_time >= 1.0:\n",
    "        print(f\"FPS: {frame_count}\")\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "\n",
    "    landmark_row = None\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            landmark_row = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmark_row.extend([lm.x, lm.y, lm.z])\n",
    "            break\n",
    "\n",
    "    # ‚îÄ‚îÄ RECORDING GESTURE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if recording:\n",
    "        if landmark_row:\n",
    "            buffer.append(landmark_row)\n",
    "            valid_frames += 1\n",
    "            cv2.putText(frame, f\"Recording ({len(buffer)}/{SEQUENCE_LENGTH} frames)\",\n",
    "                        (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            buffer.append([0] * 63)\n",
    "            cv2.putText(frame, \"No hand detected!\",\n",
    "                        (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if len(buffer) >= SEQUENCE_LENGTH:\n",
    "            sequence = np.array(buffer)\n",
    "            if sequence.shape == (SEQUENCE_LENGTH, 63):\n",
    "                if valid_frames >= MIN_VALID_FRAMES:\n",
    "                    is_static_gesture = GESTURE_NAME in [\"like\", \"dislike\"]\n",
    "                    if is_static_gesture or check_movement(sequence):\n",
    "                        # Save original sequence\n",
    "                        np.savetxt(f\"{SAVE_DIR}/{sample_count}_original.csv\", sequence, delimiter=\",\")\n",
    "                        print(f\"‚úÖ Saved original sequence: {SAVE_DIR}/{sample_count}_original.csv\")\n",
    "                        # Save augmented sequences\n",
    "                        for i in range(1, NUM_VARIATIONS):\n",
    "                            augmented_sequence = augment_sequence(sequence)\n",
    "                            np.savetxt(f\"{SAVE_DIR}/{sample_count}_{i}.csv\", augmented_sequence, delimiter=\",\")\n",
    "                            print(f\"‚úÖ Saved augmented sequence: {SAVE_DIR}/{sample_count}_{i}.csv\")\n",
    "                        sample_count += 1\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Not enough movement (max range < {MOVEMENT_THRESHOLD}). Try again.\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Not enough valid frames ({valid_frames}/{MIN_VALID_FRAMES}). Try again.\")\n",
    "            buffer.clear()\n",
    "            valid_frames = 0\n",
    "            recording = False\n",
    "            if sample_count >= MAX_RECORDINGS:\n",
    "                print(\"üü° All recordings done!\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"üü° Stopped recording. Press 's' for next sequence.\")\n",
    "    else:\n",
    "        status = \"Idle - Press 's' to record\"\n",
    "        cv2.putText(frame, status, (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 100, 255), 2)\n",
    "\n",
    "    cv2.imshow(f\"Gesture Recorder: {GESTURE_NAME}\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s') and not recording and sample_count < MAX_RECORDINGS:\n",
    "        recording = True\n",
    "        buffer.clear()\n",
    "        valid_frames = 0\n",
    "        print(\"üî¥ Started recording... Perform the gesture now.\")\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ee7ef29-9724-4b54-8963-770e56cf4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∏ Recording 5 performances for gesture: peace\n",
      "Each performance will save 10 files (1 original + 9 augmented).\n",
      "üì∏ Press 's' to start recording a gesture.\n",
      "‚ùå Press 'q' to quit.\n",
      "FPS: 18\n",
      "FPS: 30\n",
      "üî¥ Started recording... Perform the gesture now.\n",
      "FPS: 31\n",
      "FPS: 30\n",
      "‚ö†Ô∏è Not enough movement (max range < 0.1). Try again.\n",
      "üü° Stopped recording. Press 's' for next sequence.\n",
      "FPS: 31\n"
     ]
    }
   ],
   "source": [
    "#This is the dataset for recording STATIC GESTURES\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# ‚îÄ‚îÄ DETECT JUPYTER ENVIRONMENT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        get_ipython()\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "# ‚îÄ‚îÄ CONFIG FOR JUPYTER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "GESTURE_NAME = \"peace\"  # Change this for each gesture\n",
    "MAX_RECORDINGS = 5  # Number of gesture performances\n",
    "NUM_VARIATIONS = 10  # Total files per performance (1 original + 9 augmented)\n",
    "\n",
    "# ‚îÄ‚îÄ PARSE ARGUMENTS FOR COMMAND LINE ‚îÄ‚îÄ‚îÄ\n",
    "if not is_jupyter():\n",
    "    parser = argparse.ArgumentParser(description=\"Record gesture sequences for dataset creation.\")\n",
    "    parser.add_argument(\"--gesture\", type=str, default=\"like\", help=\"Name of the gesture to record (e.g., swipe_right, like).\")\n",
    "    parser.add_argument(\"--samples\", type=int, default=5, help=\"Number of gesture performances to record.\")\n",
    "    parser.add_argument(\"--variations\", type=int, default=10, help=\"Number of files to save per performance (1 original + augmented).\")\n",
    "    args = parser.parse_args()\n",
    "    GESTURE_NAME = args.gesture\n",
    "    MAX_RECORDINGS = args.samples\n",
    "    NUM_VARIATIONS = args.variations\n",
    "\n",
    "# ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "SEQUENCE_LENGTH = 60\n",
    "SAVE_DIR = f\"dataset/{GESTURE_NAME}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "MIN_VALID_FRAMES = 50\n",
    "MOVEMENT_THRESHOLD = 0.1\n",
    "AUGMENTATION_NOISE = 0.01  # Reduced noise for static gestures\n",
    "\n",
    "# ‚îÄ‚îÄ INIT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                       min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "buffer = deque(maxlen=SEQUENCE_LENGTH)\n",
    "recording = False\n",
    "sample_count = 0\n",
    "valid_frames = 0\n",
    "\n",
    "# FPS counter\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "def augment_sequence(sequence, noise_level=AUGMENTATION_NOISE):\n",
    "    \"\"\"Generate an augmented version of the sequence by adding noise.\"\"\"\n",
    "    augmented = sequence.copy()\n",
    "    noise = np.random.uniform(-noise_level, noise_level, sequence.shape)\n",
    "    augmented += noise\n",
    "    augmented[:, ::3] = np.clip(augmented[:, ::3], 0, 1)  # x\n",
    "    augmented[:, 1::3] = np.clip(augmented[:, 1::3], 0, 1)  # y\n",
    "    return augmented\n",
    "\n",
    "def check_movement(sequence, threshold=MOVEMENT_THRESHOLD):\n",
    "    \"\"\"Check if the sequence has significant movement (for dynamic gestures).\"\"\"\n",
    "    sequence = np.array(sequence)\n",
    "    x_coords = sequence[:, ::3]\n",
    "    x_range = np.ptp(x_coords, axis=0).max()\n",
    "    y_coords = sequence[:, 1::3]\n",
    "    y_range = np.ptp(y_coords, axis=0).max()\n",
    "    return max(x_range, y_range) >= threshold\n",
    "\n",
    "print(f\"üì∏ Recording {MAX_RECORDINGS} performances for gesture: {GESTURE_NAME}\")\n",
    "print(f\"Each performance will save {NUM_VARIATIONS} files (1 original + {NUM_VARIATIONS-1} augmented).\")\n",
    "print(\"üì∏ Press 's' to start recording a gesture.\")\n",
    "print(\"‚ùå Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_count += 1\n",
    "    if time.time() - start_time >= 1.0:\n",
    "        print(f\"FPS: {frame_count}\")\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb)\n",
    "\n",
    "    landmark_row = None\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            landmark_row = []\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmark_row.extend([lm.x, lm.y, lm.z])\n",
    "            break\n",
    "\n",
    "    # ‚îÄ‚îÄ RECORDING GESTURE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    if recording:\n",
    "        if landmark_row:\n",
    "            buffer.append(landmark_row)\n",
    "            valid_frames += 1\n",
    "            cv2.putText(frame, f\"Recording ({len(buffer)}/{SEQUENCE_LENGTH} frames)\",\n",
    "                        (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            buffer.append([0] * 63)\n",
    "            cv2.putText(frame, \"No hand detected!\",\n",
    "                        (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if len(buffer) >= SEQUENCE_LENGTH:\n",
    "            sequence = np.array(buffer)\n",
    "            if sequence.shape == (SEQUENCE_LENGTH, 63):\n",
    "                if valid_frames >= MIN_VALID_FRAMES:\n",
    "                    is_static_gesture = GESTURE_NAME in [\"like\", \"dislike\"]\n",
    "                    # Skip movement check for static gestures\n",
    "                    if is_static_gesture or check_movement(sequence):\n",
    "                        # Save original sequence\n",
    "                        np.savetxt(f\"{SAVE_DIR}/{sample_count}_original.csv\", sequence, delimiter=\",\")\n",
    "                        print(f\"‚úÖ Saved original sequence: {SAVE_DIR}/{sample_count}_original.csv\")\n",
    "                        # Save augmented sequences\n",
    "                        for i in range(1, NUM_VARIATIONS):\n",
    "                            augmented_sequence = augment_sequence(sequence)\n",
    "                            np.savetxt(f\"{SAVE_DIR}/{sample_count}_{i}.csv\", augmented_sequence, delimiter=\",\")\n",
    "                            print(f\"‚úÖ Saved augmented sequence: {SAVE_DIR}/{sample_count}_{i}.csv\")\n",
    "                        sample_count += 1\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è Not enough movement (max range < {MOVEMENT_THRESHOLD}). Try again.\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Not enough valid frames ({valid_frames}/{MIN_VALID_FRAMES}). Try again.\")\n",
    "            buffer.clear()\n",
    "            valid_frames = 0\n",
    "            recording = False\n",
    "            if sample_count >= MAX_RECORDINGS:\n",
    "                print(\"üü° All recordings done!\")\n",
    "                break\n",
    "            else:\n",
    "                print(\"üü° Stopped recording. Press 's' for next sequence.\")\n",
    "    else:\n",
    "        status = \"Idle - Press 's' to record\"\n",
    "        cv2.putText(frame, status, (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 100, 255), 2)\n",
    "\n",
    "    cv2.imshow(f\"Gesture Recorder: {GESTURE_NAME}\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('s') and not recording and sample_count < MAX_RECORDINGS:\n",
    "        recording = True\n",
    "        buffer.clear()\n",
    "        valid_frames = 0\n",
    "        print(\"üî¥ Started recording... Perform the gesture now.\")\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "hands.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2cd137-b59c-4831-b773-eb559d32ad34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "üñê Gesture Env",
   "language": "python",
   "name": "gesture_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
