{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9776677e-5db6-4123-81a8-95e60ec5c7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:22:44] Recording 5 performances for dynamic gesture: sos\n",
      "[2025-05-13 19:22:44] Each performance will save 10 files (1 original + 9 augmented).\n",
      "[2025-05-13 19:22:44] Files will be saved in: dataset/dynamic/sos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to start recording a gesture.\n",
      "Press 'i' to show info about the current gesture\n",
      "Press 'q' to quit.\n",
      "Countdown started... Get ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:22:50] Started recording... Perform the gesture now.\n",
      "[2025-05-13 19:22:52] Saved original sequence: dataset/dynamic/sos/0_original.csv\n",
      "[2025-05-13 19:22:52] Stopped recording. Press 's' for next sequence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown started... Get ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:22:57] Started recording... Perform the gesture now.\n",
      "[2025-05-13 19:22:59] Saved original sequence: dataset/dynamic/sos/1_original.csv\n",
      "[2025-05-13 19:22:59] Stopped recording. Press 's' for next sequence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown started... Get ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:23:04] Started recording... Perform the gesture now.\n",
      "[2025-05-13 19:23:06] Saved original sequence: dataset/dynamic/sos/2_original.csv\n",
      "[2025-05-13 19:23:06] Stopped recording. Press 's' for next sequence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown started... Get ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:23:10] Started recording... Perform the gesture now.\n",
      "[2025-05-13 19:23:12] Saved original sequence: dataset/dynamic/sos/3_original.csv\n",
      "[2025-05-13 19:23:12] Stopped recording. Press 's' for next sequence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countdown started... Get ready!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-13 19:23:17] Started recording... Perform the gesture now.\n",
      "[2025-05-13 19:23:19] Saved original sequence: dataset/dynamic/sos/4_original.csv\n",
      "[2025-05-13 19:23:19] All recordings done!\n",
      "[2025-05-13 19:23:19] Session ended. Recorded 5/5 samples for sos.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import deque\n",
    "import time\n",
    "import sys\n",
    "import argparse\n",
    "import datetime\n",
    "from scipy import interpolate\n",
    "import json\n",
    "import logging\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "# â”€â”€ DETECT JUPYTER ENVIRONMENT â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def is_jupyter():\n",
    "    try:\n",
    "        get_ipython()\n",
    "        return True\n",
    "    except NameError:\n",
    "        return False\n",
    "\n",
    "# â”€â”€ CONFIG FOR JUPYTER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "GESTURE_NAME = \"sos\"  # Change this for each gesture\n",
    "GESTURE_TYPE = \"dynamic\"  # \"static\" or \"dynamic\"\n",
    "MAX_RECORDINGS = 5      # Number of gesture performances\n",
    "NUM_VARIATIONS = 10     # Total files per performance (1 original + 9 augmented)\n",
    "\n",
    "# â”€â”€ PARSE ARGUMENTS FOR COMMAND LINE â”€â”€â”€\n",
    "if not is_jupyter():\n",
    "    parser = argparse.ArgumentParser(description=\"Record gesture sequences for dataset creation.\")\n",
    "    parser.add_argument(\"--gesture\", type=str, required=True, help=\"Name of the gesture to record (e.g., swipe_right, peace).\")\n",
    "    parser.add_argument(\"--type\", type=str, choices=[\"static\", \"dynamic\"], required=True, help=\"Type of gesture: static or dynamic.\")\n",
    "    parser.add_argument(\"--samples\", type=int, default=5, help=\"Number of gesture performances to record.\")\n",
    "    parser.add_argument(\"--variations\", type=int, default=10, help=\"Number of files to save per performance (1 original + augmented).\")\n",
    "    parser.add_argument(\"--length\", type=int, default=60, help=\"Target length of sequence in frames.\")\n",
    "    args = parser.parse_args()\n",
    "    GESTURE_NAME = args.gesture\n",
    "    GESTURE_TYPE = args.type\n",
    "    MAX_RECORDINGS = args.samples\n",
    "    NUM_VARIATIONS = args.variations\n",
    "    SEQUENCE_LENGTH = args.length\n",
    "\n",
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "SEQUENCE_LENGTH = 60 if 'SEQUENCE_LENGTH' not in locals() else SEQUENCE_LENGTH\n",
    "SEQUENCE_LENGTH_RANGE = 10  # Allow sequences to be +/- this many frames\n",
    "BASE_SAVE_DIR = \"dataset\"\n",
    "SAVE_DIR = f\"{BASE_SAVE_DIR}/{GESTURE_TYPE}/{GESTURE_NAME}\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "MIN_VALID_FRAMES = int(SEQUENCE_LENGTH * 0.7)  # Lowered to 70% for faster gestures\n",
    "MOVEMENT_THRESHOLD = 0.15 if GESTURE_TYPE == \"dynamic\" else 0.05\n",
    "AUGMENTATION_NOISE = 0.02 if GESTURE_TYPE == \"dynamic\" else 0.01\n",
    "SMOOTH_JITTER = True  # Apply light Gaussian smoothing to temporal jitter\n",
    "LOG_FILE = f\"{BASE_SAVE_DIR}/logs.txt\"\n",
    "\n",
    "# â”€â”€ SETUP LOGGING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE, encoding='utf-8'),  # Use utf-8 for file\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# â”€â”€ INIT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1,\n",
    "                       min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "buffer = []  # Use list instead of deque to avoid premature frame dropping\n",
    "recording = False\n",
    "countdown_active = False\n",
    "countdown_start = 0\n",
    "sample_count = 0\n",
    "valid_frames = 0\n",
    "hands_visible_frames = 0\n",
    "quality_issues = []\n",
    "last_valid_frame = None  # Store last valid landmarks\n",
    "\n",
    "# FPS counter\n",
    "start_time = time.time()\n",
    "frame_count = 0\n",
    "\n",
    "# Create log directory\n",
    "os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)\n",
    "\n",
    "def log_message(message):\n",
    "    \"\"\"Log message with timestamp.\"\"\"\n",
    "    logger.info(message)\n",
    "\n",
    "def normalize_landmarks(landmarks):\n",
    "    \"\"\"Normalize landmarks relative to wrist position and hand size.\"\"\"\n",
    "    landmarks = np.array(landmarks).reshape(-1, 3)\n",
    "    wrist = landmarks[0]\n",
    "    normalized = landmarks - wrist\n",
    "    scale_reference = np.linalg.norm(landmarks[9] - wrist)\n",
    "    if scale_reference > 0:\n",
    "        normalized = normalized / scale_reference\n",
    "    return normalized.flatten()\n",
    "\n",
    "def check_hand_quality(landmarks):\n",
    "    \"\"\"Check if hand landmarks are of good quality.\"\"\"\n",
    "    landmarks = np.array(landmarks).reshape(-1, 3)\n",
    "    issues = []\n",
    "    x_coords = landmarks[:, 0]\n",
    "    y_coords = landmarks[:, 1]\n",
    "    if np.min(x_coords) < 0.05 or np.max(x_coords) > 0.95:\n",
    "        issues.append(\"Hand near horizontal edge\")\n",
    "    if np.min(y_coords) < 0.05 or np.max(y_coords) > 0.95:\n",
    "        issues.append(\"Hand near vertical edge\")\n",
    "    return issues\n",
    "\n",
    "def check_movement(sequence, threshold=MOVEMENT_THRESHOLD):\n",
    "    \"\"\"Check if the sequence has significant movement.\"\"\"\n",
    "    sequence = np.array(sequence)\n",
    "    x_coords = sequence[:, ::3]\n",
    "    x_range = np.ptp(x_coords, axis=0).max()\n",
    "    y_coords = sequence[:, 1::3]\n",
    "    y_range = np.ptp(y_coords, axis=0).max()\n",
    "    return max(x_range, y_range) >= threshold, max(x_range, y_range)\n",
    "\n",
    "def preprocess_sequence(sequence, target_length=SEQUENCE_LENGTH):\n",
    "    \"\"\"Resample sequence to target length using interpolation.\"\"\"\n",
    "    if len(sequence) == target_length:\n",
    "        return np.array(sequence)\n",
    "    \n",
    "    orig_time = np.linspace(0, 1, len(sequence))\n",
    "    new_time = np.linspace(0, 1, target_length)\n",
    "    sequence = np.array(sequence)\n",
    "    interp_sequence = np.zeros((target_length, sequence.shape[1]))\n",
    "    \n",
    "    for i in range(sequence.shape[1]):\n",
    "        interp_func = interpolate.interp1d(orig_time, sequence[:, i])\n",
    "        interp_sequence[:, i] = interp_func(new_time)\n",
    "        \n",
    "    return interp_sequence\n",
    "\n",
    "def augment_sequence(sequence, noise_level=AUGMENTATION_NOISE):\n",
    "    \"\"\"Generate an augmented version of the sequence.\"\"\"\n",
    "    sequence = np.array(sequence)\n",
    "    choice = np.random.randint(0, 4)\n",
    "    \n",
    "    if choice == 0:\n",
    "        noise = np.random.uniform(-noise_level, noise_level, sequence.shape)\n",
    "        augmented = sequence + noise\n",
    "        \n",
    "    elif choice == 1:\n",
    "        augmented = np.copy(sequence)\n",
    "        shift = np.random.randint(-2, 3)\n",
    "        if shift > 0:\n",
    "            augmented[shift:, :] = sequence[:-shift, :]\n",
    "            for i in range(shift):\n",
    "                augmented[i, :] = sequence[0, :]\n",
    "        elif shift < 0:\n",
    "            augmented[:shift, :] = sequence[-shift:, :]\n",
    "            for i in range(-shift):\n",
    "                augmented[sequence.shape[0]-i-1, :] = sequence[-1, :]\n",
    "        if SMOOTH_JITTER:\n",
    "            for i in range(augmented.shape[1]):\n",
    "                augmented[:, i] = gaussian_filter1d(augmented[:, i], sigma=0.5)\n",
    "        \n",
    "    elif choice == 2:\n",
    "        scale_factor = np.random.uniform(0.95, 1.05)\n",
    "        augmented = sequence * scale_factor\n",
    "        \n",
    "    elif choice == 3:\n",
    "        augmented = np.copy(sequence)\n",
    "        num_landmarks = sequence.shape[1] // 3\n",
    "        landmark_to_zero = np.random.randint(1, num_landmarks)\n",
    "        augmented[:, landmark_to_zero*3:landmark_to_zero*3+3] = 0\n",
    "    \n",
    "    augmented[:, ::3] = np.clip(augmented[:, ::3], 0, 1)\n",
    "    augmented[:, 1::3] = np.clip(augmented[:, 1::3], 0, 1)\n",
    "    return augmented\n",
    "\n",
    "def draw_hand_box(frame, landmarks):\n",
    "    \"\"\"Draw a bounding box around the hand.\"\"\"\n",
    "    if landmarks:\n",
    "        landmarks_array = np.array(landmarks).reshape(-1, 3)\n",
    "        x_coords = landmarks_array[:, 0]\n",
    "        y_coords = landmarks_array[:, 1]\n",
    "        h, w, _ = frame.shape\n",
    "        x_min = int(np.min(x_coords) * w) - 10\n",
    "        x_max = int(np.max(x_coords) * w) + 10\n",
    "        y_min = int(np.min(y_coords) * h) - 10\n",
    "        y_max = int(np.max(y_coords) * h) + 10\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "        quality_color = (0, 255, 0)\n",
    "        if x_min < 10 or y_min < 10 or x_max > w-10 or y_max > h-10:\n",
    "            quality_color = (0, 165, 255)\n",
    "        cv2.circle(frame, (x_min, y_min-10), 5, quality_color, -1)\n",
    "\n",
    "def save_metadata(sample_index, movement_amount=None):\n",
    "    \"\"\"Save metadata for this recording session.\"\"\"\n",
    "    metadata = {\n",
    "        \"gesture_name\": GESTURE_NAME,\n",
    "        \"gesture_type\": GESTURE_TYPE,\n",
    "        \"date_recorded\": datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"sequence_length\": SEQUENCE_LENGTH,\n",
    "        \"quality_issues\": quality_issues,\n",
    "        \"movement_amount\": movement_amount\n",
    "    }\n",
    "    with open(f\"{SAVE_DIR}/{sample_index}_metadata.json\", \"w\", encoding='utf-8') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "# Main info display\n",
    "log_message(f\"Recording {MAX_RECORDINGS} performances for {GESTURE_TYPE} gesture: {GESTURE_NAME}\")\n",
    "log_message(f\"Each performance will save {NUM_VARIATIONS} files (1 original + {NUM_VARIATIONS-1} augmented).\")\n",
    "log_message(f\"Files will be saved in: {SAVE_DIR}\")\n",
    "print(\"Press 's' to start recording a gesture.\")\n",
    "print(\"Press 'i' to show info about the current gesture\")\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if time.time() - start_time >= 1.0:\n",
    "            fps = frame_count\n",
    "            frame_count = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb)\n",
    "\n",
    "        landmark_row = None\n",
    "        raw_landmarks = None\n",
    "        hand_issues = []\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                raw_landmarks = []\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    raw_landmarks.extend([lm.x, lm.y, lm.z])\n",
    "                landmark_row = normalize_landmarks(raw_landmarks).tolist()\n",
    "                hand_issues = check_hand_quality(raw_landmarks)\n",
    "                draw_hand_box(frame, raw_landmarks)\n",
    "                last_valid_frame = landmark_row  # Update last valid frame\n",
    "                break\n",
    "\n",
    "        # â”€â”€ COUNTDOWN LOGIC â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        if countdown_active:\n",
    "            elapsed = time.time() - countdown_start\n",
    "            countdown_secs = 3 - int(elapsed)\n",
    "            if countdown_secs > 0:\n",
    "                cv2.putText(frame, str(countdown_secs),\n",
    "                           (frame.shape[1]//2-50, frame.shape[0]//2),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 4, (255, 0, 0), 5)\n",
    "            else:\n",
    "                countdown_active = False\n",
    "                recording = True\n",
    "                buffer = []\n",
    "                valid_frames = 0\n",
    "                hands_visible_frames = 0\n",
    "                quality_issues = []\n",
    "                last_valid_frame = None\n",
    "                log_message(\"Started recording... Perform the gesture now.\")\n",
    "\n",
    "        # â”€â”€ RECORDING GESTURE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        elif recording:\n",
    "            if landmark_row:\n",
    "                buffer.append(landmark_row)\n",
    "                valid_frames += 1\n",
    "                hands_visible_frames += 1\n",
    "                if hand_issues:\n",
    "                    quality_issues.extend(hand_issues)\n",
    "                cv2.putText(frame, f\"Recording ({len(buffer)}/{SEQUENCE_LENGTH} frames)\",\n",
    "                           (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                if hand_issues:\n",
    "                    issue_text = \", \".join(hand_issues)\n",
    "                    cv2.putText(frame, f\"Issue: {issue_text}\",\n",
    "                               (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)\n",
    "            else:\n",
    "                # Use last valid frame if available, else zeros\n",
    "                frame_to_append = last_valid_frame if last_valid_frame else [0] * 63\n",
    "                buffer.append(frame_to_append)\n",
    "                cv2.putText(frame, \"No hand detected!\",\n",
    "                           (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Check if we should stop recording\n",
    "            min_frames = SEQUENCE_LENGTH - SEQUENCE_LENGTH_RANGE\n",
    "            max_frames = SEQUENCE_LENGTH + SEQUENCE_LENGTH_RANGE\n",
    "\n",
    "            if len(buffer) >= min_frames and hands_visible_frames >= MIN_VALID_FRAMES:\n",
    "                stop_recording = False\n",
    "                sequence = buffer[:max_frames]  # Cap to max frames\n",
    "\n",
    "                if len(buffer) >= max_frames:\n",
    "                    stop_recording = True\n",
    "                elif GESTURE_TYPE == \"static\" and len(buffer) >= SEQUENCE_LENGTH:\n",
    "                    stop_recording = True\n",
    "                elif GESTURE_TYPE == \"dynamic\":\n",
    "                    # Early stop for dynamic gestures with sufficient movement\n",
    "                    has_movement, movement_amount = check_movement(sequence)\n",
    "                    if has_movement and len(buffer) >= MIN_VALID_FRAMES:\n",
    "                        stop_recording = True\n",
    "\n",
    "                if stop_recording:\n",
    "                    if GESTURE_TYPE == \"dynamic\":\n",
    "                        has_movement, movement_amount = check_movement(sequence)\n",
    "                        if not has_movement:\n",
    "                            log_message(f\"Not enough movement (max range: {movement_amount:.3f} < {MOVEMENT_THRESHOLD}). Try again.\")\n",
    "                            buffer = []\n",
    "                            valid_frames = 0\n",
    "                            hands_visible_frames = 0\n",
    "                            recording = False\n",
    "                            continue\n",
    "\n",
    "                    sequence = preprocess_sequence(sequence, SEQUENCE_LENGTH)\n",
    "                    np.savetxt(f\"{SAVE_DIR}/{sample_count}_original.csv\", sequence, delimiter=\",\")\n",
    "                    log_message(f\"Saved original sequence: {SAVE_DIR}/{sample_count}_original.csv\")\n",
    "\n",
    "                    for i in range(1, NUM_VARIATIONS):\n",
    "                        augmented_sequence = augment_sequence(sequence)\n",
    "                        np.savetxt(f\"{SAVE_DIR}/{sample_count}_{i}.csv\", augmented_sequence, delimiter=\",\")\n",
    "\n",
    "                    if quality_issues:\n",
    "                        unique_issues = list(set(quality_issues))\n",
    "                        log_message(f\"Recording had some quality issues: {', '.join(unique_issues)}\")\n",
    "\n",
    "                    save_metadata(sample_count, movement_amount if GESTURE_TYPE == \"dynamic\" else None)\n",
    "                    sample_count += 1\n",
    "                    buffer = []\n",
    "                    valid_frames = 0\n",
    "                    hands_visible_frames = 0\n",
    "                    recording = False\n",
    "\n",
    "                    if sample_count >= MAX_RECORDINGS:\n",
    "                        log_message(\"All recordings done!\")\n",
    "                        break\n",
    "                    else:\n",
    "                        log_message(\"Stopped recording. Press 's' for next sequence.\")\n",
    "\n",
    "            progress = min(len(buffer) / SEQUENCE_LENGTH, 1.0)\n",
    "            cv2.rectangle(frame, (0, frame.shape[0]-10),\n",
    "                         (int(frame.shape[1] * progress), frame.shape[0]),\n",
    "                         (0, 255, 0), -1)\n",
    "        else:\n",
    "            status = \"Idle - Press 's' to record\"\n",
    "            cv2.putText(frame, status, (10, 40),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 100, 255), 2)\n",
    "            if landmark_row and hand_issues:\n",
    "                issue_text = \", \".join(hand_issues)\n",
    "                cv2.putText(frame, f\"Issue: {issue_text}\",\n",
    "                           (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Recorded: {sample_count}/{MAX_RECORDINGS}\",\n",
    "                   (frame.shape[1]-250, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.7, (255, 255, 255), 2)\n",
    "        gesture_info = f\"Gesture: {GESTURE_NAME} ({GESTURE_TYPE})\"\n",
    "        cv2.putText(frame, gesture_info,\n",
    "                   (10, frame.shape[0]-20), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.7, (255, 255, 255), 2)\n",
    "        cv2.imshow(f\"Gesture Recorder: {GESTURE_NAME} ({GESTURE_TYPE})\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('s') and not recording and not countdown_active and sample_count < MAX_RECORDINGS:\n",
    "            countdown_active = True\n",
    "            countdown_start = time.time()\n",
    "            print(\"Countdown started... Get ready!\")\n",
    "        elif key == ord('i'):\n",
    "            print(f\"\\n=== GESTURE INFO ===\")\n",
    "            print(f\"Name: {GESTURE_NAME}\")\n",
    "            print(f\"Type: {GESTURE_TYPE}\")\n",
    "            print(f\"Progress: {sample_count}/{MAX_RECORDINGS} recordings\")\n",
    "            print(f\"Saving to: {SAVE_DIR}\")\n",
    "            print(f\"Min valid frames: {MIN_VALID_FRAMES}\")\n",
    "            if GESTURE_TYPE == \"dynamic\":\n",
    "                print(f\"Movement threshold: {MOVEMENT_THRESHOLD}\")\n",
    "            print(\"===================\\n\")\n",
    "        elif key == ord('q'):\n",
    "            if recording:\n",
    "                confirm = input(\"Recording in progress. Are you sure you want to quit? (y/n): \")\n",
    "                if confirm.lower() != 'y':\n",
    "                    continue\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    hands.close()\n",
    "\n",
    "log_message(f\"Session ended. Recorded {sample_count}/{MAX_RECORDINGS} samples for {GESTURE_NAME}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ðŸ– Gesture Env",
   "language": "python",
   "name": "gesture_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
